\documentclass[15pt]{book}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{fancyvrb}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{placeins}
\pgfplotsset{compat=1.11}
\pagestyle{fancy}
\fancyhead{}
\fancyfoot{}
\fancyhead[L]{QuantiT design document}
\fancyhead[R]{Date: \today}
\fancyfoot[C]{\thepage}
\usepackage{graphicx}

\newcommand{\ket}[1]{| #1 \rangle}

\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\begin{document}
\title{Design of QuantiT}
\author{Alexandre Foley}

\maketitle

\tableofcontents
\part{Plans}
\chapter{Design Requirements}

The goal of this library is library is to provide a framework to facilitate the implementation of tensor network methods for quantum mechanics, using Torch tensors as backend.
Without optimization for conserved quantities and symmetries, this is demonstrably an easy and effiecient procedure.
Implementing conservation law at the level of individual tensors is tricky business. Luckily we have the experience in building such class from creating DMRJulia.

QuantiT aims to offer tools for physicist to perform simulation of large-scale (larger than exact diagonalization) quantum mechanical problems in the Hamiltonian formalism. That aim is not one for a project with an end date. A modest stepping stone toward that lofty goal is to offer the basic tools of tensor network to allow more advanced user to design methods that can simulate large-scale quantum system.
To that end, we must:
\begin{itemize}
    \item create a class to represent tensors with conservation laws: the btensor.
    \item Minimally, the btensor offer the following methods or functions:
    \begin{itemize}
        \item arbitrary contraction of tensors with compatible shapes
        \item addition of tensors with same shapes
        \item reshaping
        \item multiplication with scalars
        \item element manipulation tools (emulate pytorch interface)
        \item computationnal shape manipulation tools
    \end{itemize}
    \item Implemented the linear algebra routines commonly useful in tensor network method or the btensor.
    \begin{itemize}
        \item eigenvalue decomposition (EVD)
        \item singular value decomposition (SVD)
        \item optionnally: pLQ and QRp. The rank revealing variation of the triangular decompositions QR and LQ. Cheaper to perform than SVD, and good enough most of the time.
    \end{itemize}
    \item Demonstration of the quality of implementation with the density matrix renormalization group (DMRG).
    \item User manual with examples of basic usage.
\end{itemize}
\section{Outline of the user manual}
This is an outline of the more pedagogical aspects that should be present in the user manual.
Additionnally, code documentation (doxygen) should be present.
\begin{itemize}
    \item The purpose of this library (what it currently does)
    \item How to construct a btensor
    \item basic manipulations (reshape, contraction, addition)
    \item Linear algebra routines
    \item example: construction of a MPO and a MPS
    \item example: optimizing the MPS with DMRG.
\end{itemize}
\chapter{Design Specification}
\section{btensor}
The btensor is a class that represent tensors constrained by abelian conservation laws (see sec.~\ref{sec:group} concerning abelian groups).
The internal representation is a block sparse tensor.
The conservation rule determines which block can or cannot be non-nul.
Each block is itself a tensor of the same rank as the overall tensor.

Each dimensions of the tensor are separated in sections with independent sizes, each of those section
has an associated conserved quantity. The blocks are formed by the intersection of those section.
The only block that can contain non-zero values are those that satisfy the selection rule: the sum over the
dimension of the conserved quantity must equal a specififed value (the selection rule).

Such simple selection rule can only represent Abelian symmetries.

\subsection{exemple with a rank 2 tensor}
\FloatBarrier
In fig.~\ref{fig:blockmat} a rank $2$ block tensor is sketched. The rows of this tensor are separated in 4 sections, and the columns in 3 sections.
This make up to 12 blocks, that we label by section.
Let's consider that the conserved quantity is simply an integer under the addition, that the column sections has values $[-2,-1,1]$, the row sections have the conserved quantity $[1,2,3,-1]$ and the selection rule is $0$. In that case, only the blocks $[(1,0),(0,1),(2,3)]$ can be non-zero.
\begin{figure}[h]
    \centering
    \def\svgwidth{0.75\textwidth}
    \input{matrice_bloques.eps_tex}
    \caption{ Rank 2 bloc tensor (a matrix), each of the block are simple tensors with the same rank and smaller in every dimension. The double line rectangle is the block tensor. Inside it, the blocks are separated by dashed lines. The blocks are labeled by their block position. Outside the tensor, the sections of each dimension are labeled according to the dimension number and their order. The sum of the size of each block along a given dimension is the size of the tensor in that dimension. Which of the block can be non zero is determined by the selection rule.}\label{fig:blockmat}
\end{figure}

\FloatBarrier
\subsection{Block and their storage: flat_map}
Each of the blocks are ordinary tensors, we can therefor make use of tensors implemented by just about any third party. We choose to use pytorch's because of the varied backend it allows (CPU and GPU being the most important ones) and the well used and tested interface. We can weaken the coupling to pytorch later on by using a policy template design.
A priori, the data individual tensor are allocated on the heap, therefor what we have to store is within the strucure is of a small, fixed size. Ordering of the block is a very useful property to retrieve information about a block in a reliable time, and it also allow for implementing contraction of two tensor in a minimal number of traversal.
Keeping traversal time short can be achieved by using a memory local structure for storage.
No structure in the std library are available with both the locality property and the ordering, we must implement our own to avoid a compromise. 

The interface of this structure should mimic as closely as possible that of std::map. Locality implies that iterator invalidation behavior will be that of std::vector.

\subsection{Detailed specification}
\begin{table}
    \begin{tabular}{|l|}
        \hline
        \multicolumn{1}{|c|}{btensor}\\
        
        
    \end{tabular}
\end{table}

\section{conservation rule}
The relevent conserved quantities that should be used depends heavily on the particularities of the problem at hand.
Consequently the computer representation of those must be built with flexibility in mind.

\chapter{Tests}
\chapter{Practicalities: project structure}
\part{Detailed design}
\chapter{Tensor Networks, in general}
Tensor network method need only a few operation to be workable: tensor contraction, tensor reshape, dimension permute, eigenvalue decomposion (EVD) and a singular value decomposion (SVD).
Other decompostion can be useful and are sometime optimal, but SVD can be used almost universally instead. For exemple rank revealing QR and rank rank revealing LQ decompision can be used instead of SVD.
Rank revealing QR and rank revealing LQ are optimal to truncate the orthogonality center of a MPS and move it right (with QR) or left (with LQ). A typical implementation of SVD involve many calls to QR or LQ.
\section{torch::Tensor for Tensor Network}
The torch library offer the basic facilities needed to implement tensor network: Tensors and the basic operation named previously. What is missing is tensors contrained by the conservation law of a problem and a way to express the algebra of an arbitrary set of conserved quantities.


\chapter{Conserved quantities (quantum numbers)}

\section{Abelian vs non-Abelian}\label{sec:group}
Abelian conserved quantities are conserved quantities that emerge from a symmetry corresponding to an Abelian group: every element of the group commute with one another. This property leads to many others and lead to many simplifications. The most important such simplification for conserving tensors is the following property: the product tensor product of two eigenstate of symmetry is also an eigenstate of the symmetry. Lets consider for exemple particle numbers:
\begin{equation}
    \ket{n_A} \otimes \ket{m_B} = \ket{n+m_{AB}}
\end{equation}
The tensor product of a state with n particles in Hilbert space A with a state with m particles in Hilbert space is a state with n+m particles in the tensor product space. The same cannot be said for non-abelian symmetries.

Let's briefly consider an exemple with the total angular momentum:
\begin{equation}
    \ket{J_A,s_A} \otimes \ket{J_B,s_B} = \sum_{J_{AB} = |J_A - J_B|}^{J_A + J_B} \lambda_{J_{AB},s_{A}+s_B} \ket{J_AB,s_A+s_b}
\end{equation}
The tensor product of two eigenstate of the total angular momentum is not an eigenstate of the total angular momentum, and the precise combination depends on the angular momentum along the quantification axis .
\section{Design of the conserved quantities}

For abelian symmetries, the quantum number of any such group can be composed of the tensor product of two types of simple abelian group: the finite cyclic group, and the infinite group of the integer under the addition [[citation needed]].

\subsection{Design outline for non-Abelian symmetries}

\end{document}