<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>QuantiT: /home/alex/project/quantt/include/blockTensor/LinearAlgebra.h Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">QuantiT
   &#160;<span id="projectnumber">0.1</span>
   </div>
   <div id="projectbrief">A tensor network library for quantum mechanics</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="dir_7a13f9132e4f8cac71358e1544611c31.html">blockTensor</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">LinearAlgebra.h</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">/*</span></div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment"> * File: LinearAlgebra.h</span></div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment"> * Project: QuantiT</span></div>
<div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment"> * File Created: Thursday, 13th May 2021 11:22:38 am</span></div>
<div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment"> * Author: Alexandre Foley (Alexandre.foley@usherbrooke.ca)</span></div>
<div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment"> * Copyright (c) 2021 Alexandre Foley</span></div>
<div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="comment"> * Licensed under GPL v3</span></div>
<div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="comment"> */</span></div>
<div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160; </div>
<div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="preprocessor">#ifndef BTENSORLINEARALGEBRA_H</span></div>
<div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="preprocessor">#define BTENSORLINEARALGEBRA_H</span></div>
<div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160; </div>
<div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="preprocessor">#include &quot;blockTensor/btensor.h&quot;</span></div>
<div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="preprocessor">#include &quot;doctest/doctest_proxy.h&quot;</span></div>
<div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="preprocessor">#include &lt;ATen/Functions.h&gt;</span></div>
<div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="preprocessor">#include &lt;ATen/TensorIndexing.h&gt;</span></div>
<div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="preprocessor">#include &lt;fmt/core.h&gt;</span></div>
<div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="preprocessor">#include &lt;fmt/ranges.h&gt;</span></div>
<div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="preprocessor">#include &lt;ostream&gt;</span></div>
<div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160; </div>
<div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="keyword">namespace </span>quantit</div>
<div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;{</div>
<div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160; </div>
<div class="line"><a name="l00030"></a><span class="lineno"><a class="line" href="structquantit_1_1BOOL.html">   30</a></span>&#160;<span class="keyword">struct </span><a class="code" href="structquantit_1_1BOOL.html">BOOL</a></div>
<div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;{</div>
<div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;    <span class="keywordtype">bool</span> val;</div>
<div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;    <a class="code" href="structquantit_1_1BOOL.html">BOOL</a>(<span class="keywordtype">bool</span> _val) noexcept : val(_val) {}</div>
<div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;    <span class="keyword">operator</span> bool() <span class="keyword">const</span> noexcept { <span class="keywordflow">return</span> val; }</div>
<div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;};</div>
<div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;std::tuple&lt;btensor, btensor, btensor&gt; svd(<span class="keyword">const</span> <a class="code" href="classquantit_1_1btensor.html">btensor</a> &amp;tensor, <a class="code" href="structquantit_1_1BOOL.html">BOOL</a> some = <span class="keyword">true</span>, <a class="code" href="structquantit_1_1BOOL.html">BOOL</a> compute_uv = <span class="keyword">true</span>);</div>
<div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160; </div>
<div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;std::tuple&lt;btensor, btensor, btensor&gt; svd(<span class="keyword">const</span> <a class="code" href="classquantit_1_1btensor.html">btensor</a> &amp;tensor, <span class="keywordtype">size_t</span> split);</div>
<div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;<span class="keyword">inline</span> std::tuple&lt;btensor, btensor, btensor&gt; svd(<span class="keyword">const</span> <a class="code" href="classquantit_1_1btensor.html">btensor</a> &amp;tensor, <span class="keywordtype">int</span> split)</div>
<div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;{</div>
<div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;    <span class="keywordflow">return</span> svd(tensor, <span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(split));</div>
<div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;}</div>
<div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160; </div>
<div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;std::tuple&lt;btensor, btensor, btensor&gt; svd(<span class="keyword">const</span> btensor &amp;A, <span class="keywordtype">size_t</span> split, btensor::Scalar tol, <span class="keywordtype">size_t</span> min_size,</div>
<div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;                                          <span class="keywordtype">size_t</span> max_size, btensor::Scalar pow = 2);</div>
<div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;<span class="keyword">inline</span> std::tuple&lt;btensor, btensor, btensor&gt; svd(<span class="keyword">const</span> btensor &amp;A, <span class="keywordtype">int</span> split, btensor::Scalar tol, <span class="keywordtype">size_t</span> min_size,</div>
<div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;                                                 <span class="keywordtype">size_t</span> max_size, btensor::Scalar pow = 2)</div>
<div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;{</div>
<div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;    <span class="keywordflow">return</span> svd(A, <span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(split), tol, min_size, max_size, pow);</div>
<div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;}</div>
<div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;std::tuple&lt;btensor, btensor, btensor&gt; svd(<span class="keyword">const</span> btensor &amp;A, <span class="keywordtype">size_t</span> split, btensor::Scalar tol, btensor::Scalar pow = 2);</div>
<div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;<span class="keyword">inline</span> std::tuple&lt;btensor, btensor, btensor&gt; svd(<span class="keyword">const</span> btensor &amp;A, <span class="keywordtype">int</span> split, btensor::Scalar tol,</div>
<div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;                                                 btensor::Scalar pow = 2)</div>
<div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;{</div>
<div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;    <span class="keywordflow">return</span> svd(A, <span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(split), tol, pow);</div>
<div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;}</div>
<div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;std::tuple&lt;btensor, btensor&gt; eigh(<span class="keyword">const</span> btensor &amp;tensor, BOOL upper = <span class="keyword">false</span>);</div>
<div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;std::tuple&lt;btensor, btensor&gt; eigh(<span class="keyword">const</span> btensor &amp;tensor, <span class="keywordtype">size_t</span> split);</div>
<div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;std::tuple&lt;btensor, btensor&gt; eigh(<span class="keyword">const</span> btensor &amp;A, <span class="keywordtype">size_t</span> split, btensor::Scalar tol, <span class="keywordtype">size_t</span> min_size,</div>
<div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;                                    <span class="keywordtype">size_t</span> max_size, btensor::Scalar pow = 1);</div>
<div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;std::tuple&lt;btensor, btensor&gt; eigh(<span class="keyword">const</span> btensor &amp;A, <span class="keywordtype">size_t</span> split, btensor::Scalar tol, btensor::Scalar pow = 1);</div>
<div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160; </div>
<div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;<span class="keyword">namespace </span>LA_helpers</div>
<div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;{</div>
<div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;btensor::block_list_t::content_t reorder_by_cvals(<span class="keyword">const</span> btensor &amp;tensor);</div>
<div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160; </div>
<div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;std::tuple&lt;torch::Tensor, btensor::index_list, std::vector&lt;std::tuple&lt;int, torch::indexing::Slice&gt;&gt;,</div>
<div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;           std::vector&lt;std::tuple&lt;int, torch::indexing::Slice&gt;&gt;&gt;</div>
<div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;compact_dense_single(<span class="keyword">typename</span> btensor::block_list_t::content_t::const_iterator start,</div>
<div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;                     <span class="keyword">typename</span> btensor::block_list_t::content_t::const_iterator end);</div>
<div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160; </div>
<div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;<span class="keyword">using</span> Slice = torch::indexing::Slice;</div>
<div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;<span class="keyword">using</span> TensInd = torch::indexing::TensorIndex;</div>
<div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;std::tuple&lt;btensor::index_list, std::array&lt;TensInd, 3&gt;&gt; build_index_slice(<span class="keyword">const</span> btensor::index_list &amp;other_indices,</div>
<div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;                                                                          <span class="keyword">const</span> std::tuple&lt;int, Slice&gt; &amp;rb_slices,</div>
<div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;                                                                          <span class="keyword">const</span> std::tuple&lt;int, Slice&gt; &amp;cb_slices);</div>
<div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160; </div>
<div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;std::vector&lt;std::tuple&lt;torch::Tensor, btensor::index_list, std::vector&lt;std::tuple&lt;int, torch::indexing::Slice&gt;&gt;,</div>
<div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;                       std::vector&lt;std::tuple&lt;int, torch::indexing::Slice&gt;&gt;&gt;&gt;</div>
<div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;compact_dense(<span class="keyword">const</span> btensor &amp;tensor);</div>
<div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;} <span class="comment">// namespace LA_helpers</span></div>
<div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160; </div>
<div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;<span class="keyword">inline</span> std::ostream &amp;operator&lt;&lt;(std::ostream &amp;out, any_quantity_cref qt)</div>
<div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;{</div>
<div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;    out &lt;&lt; fmt::format(<span class="stringliteral">&quot;{}&quot;</span>, qt);</div>
<div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;    <span class="keywordflow">return</span> out;</div>
<div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;}</div>
<div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160; </div>
<div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;std::string qformat(any_quantity_cref qt);</div>
<div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160; </div>
<div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;std::tuple&lt;btensor, btensor&gt; truncate(btensor &amp;&amp;e, btensor &amp;&amp;S, <span class="keywordtype">size_t</span> max, <span class="keywordtype">size_t</span> min,</div>
<div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;                                               btensor::Scalar tol, btensor::Scalar pow);</div>
<div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;std::tuple&lt;btensor, btensor, btensor&gt; truncate(btensor &amp;&amp;U, btensor &amp;&amp;d, btensor &amp;&amp;V, <span class="keywordtype">size_t</span> max, <span class="keywordtype">size_t</span> min,</div>
<div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;                                               btensor::Scalar tol, btensor::Scalar pow);</div>
<div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160; </div>
<div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;qtt_TEST_CASE(<span class="stringliteral">&quot;btensor Linear algebra&quot;</span>)</div>
<div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;{</div>
<div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;    qtt_SUBCASE(<span class="stringliteral">&quot;decompositions&quot;</span>)</div>
<div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;    {</div>
<div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;        <span class="keyword">using</span> cqt = conserved::C&lt;5&gt;;</div>
<div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;        <span class="keyword">using</span> index = btensor::index_list;</div>
<div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;        any_quantity selection_rule(cqt(0)); <span class="comment">// DMRJulia flux</span></div>
<div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;        btensor A({{{2, cqt(0)}, {3, cqt(1)}},</div>
<div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;                   {{1, cqt(1)}, {2, cqt(0)}, {3, cqt(-1)}, {1, cqt(1)}},</div>
<div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;                   {{3, cqt(0)}, {2, cqt(-2)}, {2, cqt(-1)}}},</div>
<div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;                  selection_rule);</div>
<div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;        A.block({0, 0, 2}) = torch::rand({2, 1, 2});</div>
<div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;        A.block({0, 1, 0}) = torch::rand({2, 2, 3});</div>
<div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;        A.block({0, 3, 2}) = torch::rand({2, 1, 2});</div>
<div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;        A.block({1, 0, 1}) = torch::rand({3, 1, 2});</div>
<div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;        A.block({1, 1, 2}) = torch::rand({3, 2, 2});</div>
<div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;        A.block({1, 2, 0}) = torch::rand({3, 3, 3});</div>
<div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;        A.block({1, 3, 1}) = torch::rand({3, 1, 2});</div>
<div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;        qtt_REQUIRE_NOTHROW(<a class="code" href="classquantit_1_1btensor.html#a5d8897e8e51c880654c5d467b2b0a8bc">btensor::throw_bad_tensor</a>(A));</div>
<div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;        <span class="keyword">auto</span> [U, d, V] = svd(A);</div>
<div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;<span class="preprocessor">#ifndef NDEBUG</span></div>
<div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;        <span class="comment">// those helpers are not in the header when not in debug mode.</span></div>
<div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;        qtt_SUBCASE(<span class="stringliteral">&quot;btensor linear algebra helpers&quot;</span>)</div>
<div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;        {</div>
<div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;            {</div>
<div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;                <span class="keyword">auto</span> reordered_block = LA_helpers::reorder_by_cvals(A);</div>
<div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;                std::vector&lt;btensor::index_list&gt; exp_blocks = {{0, 1, 0}, {1, 1, 2}, {1, 0, 1}, {1, 3, 1},</div>
<div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;                                                               {0, 0, 2}, {0, 3, 2}, {1, 2, 0}};</div>
<div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;                qtt_CHECK(exp_blocks.size() == reordered_block.size());</div>
<div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;                <span class="keywordflow">for</span> (<span class="keyword">auto</span> [block, expec] = std::make_tuple(reordered_block.begin(), exp_blocks.begin());</div>
<div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;                     block != reordered_block.end(); ++block, ++expec)</div>
<div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;                {</div>
<div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;                    <span class="comment">// auto cvals_view = A.block_quantities(std::get&lt;0&gt;(*block));</span></div>
<div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;                    <span class="comment">// fmt::print( &quot;cvals: {}\n&quot;,fmt::join(cvals_view.begin(),cvals_view.end(),&quot;,&quot;));</span></div>
<div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;                    <span class="comment">// fmt::print(&quot;block index: {}\n&quot;, std::get&lt;0&gt;(*block));</span></div>
<div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;                    qtt_CHECK(std::get&lt;0&gt;(*block) == *expec);</div>
<div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;                }</div>
<div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;                <span class="comment">// reordered_block[2:4] is a set of block with the same c_vals on the last two indices, and with the</span></div>
<div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;                <span class="comment">// same block indices for all but the last two dims.</span></div>
<div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;                <span class="keyword">auto</span> [compact_tensor, other_indices, row_block_slices, col_block_slices] =</div>
<div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;                    LA_helpers::compact_dense_single(reordered_block.begin() + 2, reordered_block.begin() + 4);</div>
<div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;                qtt_REQUIRE(other_indices.size() == 1);</div>
<div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;                <span class="keywordflow">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span> &amp;rb_slices : row_block_slices)</div>
<div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;                {</div>
<div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;                    <span class="keywordflow">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span> &amp;cb_slices : col_block_slices)</div>
<div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;                    {</div>
<div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;                        <span class="keyword">auto</span> [block_ind, slice] = LA_helpers::build_index_slice(other_indices, rb_slices, cb_slices);</div>
<div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;                        <span class="comment">// we have rebuilt the block index in block_ind. It would be good to have a function to do that.</span></div>
<div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;                        qtt_CHECK(torch::equal(A.block(block_ind), compact_tensor.index(slice)));</div>
<div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;                        <span class="comment">// then we verify that the blocks from the original tensor can be obtained from the stored</span></div>
<div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;                        <span class="comment">// slincing of the compacted tensor</span></div>
<div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;                    }</div>
<div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;                }</div>
<div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;            }</div>
<div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;            {</div>
<div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;                btensor B;</div>
<div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;                qtt_REQUIRE_NOTHROW(B = A.reshape({1})); <span class="comment">// joins dimensions 2 and 1</span></div>
<div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;                <span class="comment">// fmt::print(&quot;tensor {}\n&quot;,B);</span></div>
<div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;                <span class="keyword">auto</span> reordered_block = LA_helpers::reorder_by_cvals(B);</div>
<div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;                std::vector&lt;btensor::index_list&gt; exp_blocks = {{0, 2}, {0, 3}, {0, 11}, {1, 1},</div>
<div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;                                                               {1, 5}, {1, 6}, {1, 10}};</div>
<div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;                qtt_CHECK(exp_blocks.size() == reordered_block.size());</div>
<div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;                <span class="keywordflow">for</span> (<span class="keyword">auto</span> [block, expec] = std::make_tuple(reordered_block.begin(), exp_blocks.begin());</div>
<div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;                     block != reordered_block.end(); ++block, ++expec)</div>
<div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;                {</div>
<div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;                    <span class="comment">// auto cvals_view = B.block_quantities(std::get&lt;0&gt;(*block));</span></div>
<div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;                    <span class="comment">// fmt::print( &quot;cvals: {}\n&quot;,fmt::join(cvals_view.begin(),cvals_view.end(),&quot;,&quot;));</span></div>
<div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;                    <span class="comment">// fmt::print(&quot;block index: {}\n&quot;, std::get&lt;0&gt;(*block));</span></div>
<div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;                    qtt_CHECK(std::get&lt;0&gt;(*block) == *expec);</div>
<div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;                }</div>
<div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;                <span class="keyword">auto</span> [compact_tensor, other_indices, row_block_slices, col_block_slices] =</div>
<div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;                    LA_helpers::compact_dense_single(reordered_block.begin(), reordered_block.begin() + 3);</div>
<div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;                qtt_REQUIRE(other_indices.size() == 0);</div>
<div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;                <span class="keywordflow">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span> &amp;rb_slices : row_block_slices)</div>
<div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;                {</div>
<div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;                    <span class="keywordflow">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span> &amp;cb_slices : col_block_slices)</div>
<div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;                    {</div>
<div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;                        <span class="keyword">auto</span> [block_ind, slice] = LA_helpers::build_index_slice(other_indices, rb_slices, cb_slices);</div>
<div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;                        <span class="comment">// fmt::print(&quot;block {}, cval {}\n&quot;,block_ind,B.block_quantities(block_ind));</span></div>
<div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;                        qtt_CHECK(torch::equal(B.block(block_ind), compact_tensor.index(slice)));</div>
<div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;                        <span class="comment">// then we verify that the blocks from the original tensor can be obtained from the stored</span></div>
<div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;                        <span class="comment">// slincing of the compacted tensor</span></div>
<div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;                    }</div>
<div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;                }</div>
<div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;            }</div>
<div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;        }</div>
<div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;<span class="preprocessor">#endif </span><span class="comment">// NDEBUG</span></div>
<div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;       <span class="comment">// fmt::print(&quot;V {}\n&quot;,V);</span></div>
<div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;        qtt_CHECK_NOTHROW(<a class="code" href="classquantit_1_1btensor.html#a5d8897e8e51c880654c5d467b2b0a8bc">btensor::throw_bad_tensor</a>(U));</div>
<div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;        qtt_CHECK_NOTHROW(<a class="code" href="classquantit_1_1btensor.html#a5d8897e8e51c880654c5d467b2b0a8bc">btensor::throw_bad_tensor</a>(d));</div>
<div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;        qtt_REQUIRE_NOTHROW(<a class="code" href="classquantit_1_1btensor.html#a5d8897e8e51c880654c5d467b2b0a8bc">btensor::throw_bad_tensor</a>(V));</div>
<div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;        <span class="keyword">auto</span> d_r =</div>
<div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;            d.reshape_as(shape_from(d, btensor({{{1, d.selection_rule-&gt;neutral()}}}, d.selection_rule-&gt;neutral())))</div>
<div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;                .transpose_(-1, -2);</div>
<div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;        <span class="keyword">auto</span> Vt = V.transpose(-1, -2).conj();</div>
<div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;        <span class="keyword">auto</span> AA = U.mul(d_r).bmm(Vt);</div>
<div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;        <span class="comment">// fmt::print(&quot;U {}\n&quot;,U);</span></div>
<div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;        <span class="comment">// fmt::print(&quot;V {}\n&quot;,V);</span></div>
<div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;        <span class="keyword">auto</span> it_AA = AA.begin();</div>
<div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;        <span class="keyword">auto</span> it_A = A.begin();</div>
<div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;        qtt_REQUIRE(std::distance(it_AA, AA.end()) == std::distance(it_A, A.end()));</div>
<div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;        <span class="keywordflow">for</span> (; it_AA != AA.end(); ++it_AA, ++it_A)</div>
<div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;        {</div>
<div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;            <span class="keyword">auto</span> &amp;AA_ind = std::get&lt;0&gt;(*it_AA);</div>
<div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;            <span class="keyword">auto</span> &amp;A_ind = std::get&lt;0&gt;(*it_A);</div>
<div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;            <span class="keyword">auto</span> &amp;AA_tens = std::get&lt;1&gt;(*it_AA);</div>
<div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;            <span class="keyword">auto</span> &amp;A_tens = std::get&lt;1&gt;(*it_A);</div>
<div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;            qtt_CHECK(AA_ind == A_ind);</div>
<div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;            qtt_CHECK(torch::allclose(AA_tens, A_tens));</div>
<div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;        }</div>
<div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;        <span class="keyword">auto</span> Ut = U.transpose(-2, -1).conj();</div>
<div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;        <span class="comment">// fmt::print(&quot;Ut {}\n&quot;,Ut );</span></div>
<div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;        <span class="comment">// fmt::print(&quot;U {}\n&quot;, U);</span></div>
<div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;        <span class="keyword">auto</span> ID_u = U.bmm(Ut); <span class="comment">// ATTN! In general, Ut.bmm(Ut) != identity</span></div>
<div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;        <span class="keyword">auto</span> ID_v = Vt.bmm(V); <span class="comment">// ATTN! In general, V.bmm(Vt) != Identity</span></div>
<div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;        <span class="comment">// fmt::print(&quot;ID_U {}&quot;, ID_u);</span></div>
<div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;        <span class="keywordflow">for</span> (<span class="keyword">auto</span> &amp;block : ID_u)</div>
<div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;        {</div>
<div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;            <span class="keyword">auto</span> &amp;ind = std::get&lt;0&gt;(block);</div>
<div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;            <span class="keyword">auto</span> &amp;tens = std::get&lt;1&gt;(block);</div>
<div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;            <span class="keywordflow">if</span> (ind[ind.size() - 1] == ind[ind.size() - 2])</div>
<div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;            {</div>
<div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;                qtt_CHECK(tens.sizes()[tens.dim() - 1] == tens.sizes()[tens.dim() - 2]);</div>
<div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;                <span class="keyword">auto</span> <span class="keywordtype">id</span> = torch::eye(tens.sizes()[tens.dim() - 1]);</div>
<div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;                qtt_CHECK(torch::allclose(<span class="keywordtype">id</span>, tens));</div>
<div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;            }</div>
<div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;            <span class="keywordflow">else</span></div>
<div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;            {</div>
<div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;                <span class="keyword">auto</span> zer = torch::zeros({tens.sizes()[tens.dim() - 2], tens.sizes()[tens.dim() - 1]});</div>
<div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;                qtt_CHECK(torch::allclose(zer, tens));</div>
<div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;            }</div>
<div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;        }</div>
<div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;        <span class="comment">// fmt::print(&quot;ID_V \n{}\n\n&quot;,ID_v);</span></div>
<div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;        <span class="comment">// fmt::print(&quot;Vt \n{}\n\n&quot;,Vt);</span></div>
<div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;        <span class="comment">// fmt::print(&quot;V \n{}\n\n&quot;,V);</span></div>
<div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;        <span class="keywordflow">for</span> (<span class="keyword">auto</span> &amp;block : ID_v)</div>
<div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;        {</div>
<div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;            <span class="keyword">auto</span> &amp;ind = std::get&lt;0&gt;(block);</div>
<div class="line"><a name="l00387"></a><span class="lineno">  387</span>&#160;            <span class="keyword">auto</span> &amp;tens = std::get&lt;1&gt;(block);</div>
<div class="line"><a name="l00388"></a><span class="lineno">  388</span>&#160;            <span class="keywordflow">if</span> (ind[ind.size() - 1] == ind[ind.size() - 2])</div>
<div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;            {</div>
<div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160;                qtt_CHECK(tens.sizes()[tens.dim() - 1] == tens.sizes()[tens.dim() - 2]);</div>
<div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;                <span class="keyword">auto</span> <span class="keywordtype">id</span> = torch::eye(tens.sizes()[tens.dim() - 1]);</div>
<div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;                qtt_CHECK(torch::allclose(<span class="keywordtype">id</span>, tens));</div>
<div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;            }</div>
<div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;            <span class="keywordflow">else</span></div>
<div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;            {</div>
<div class="line"><a name="l00396"></a><span class="lineno">  396</span>&#160;                <span class="keyword">auto</span> zer = torch::zeros({tens.sizes()[tens.dim() - 2], tens.sizes()[tens.dim() - 1]});</div>
<div class="line"><a name="l00397"></a><span class="lineno">  397</span>&#160;                qtt_CHECK(torch::allclose(zer, tens));</div>
<div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160;            }</div>
<div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;        }</div>
<div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160;    }</div>
<div class="line"><a name="l00401"></a><span class="lineno">  401</span>&#160;    qtt_SUBCASE(<span class="stringliteral">&quot;tensor decomposition&quot;</span>)</div>
<div class="line"><a name="l00402"></a><span class="lineno">  402</span>&#160;    {</div>
<div class="line"><a name="l00403"></a><span class="lineno">  403</span>&#160;        <span class="keyword">using</span> cqt = conserved::C&lt;5&gt;;</div>
<div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;        <span class="keyword">using</span> index = btensor::index_list;</div>
<div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;        <span class="keywordtype">double</span> tole = 1e-5;</div>
<div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160;        any_quantity selection_rule(cqt(0)); <span class="comment">// DMRJulia flux</span></div>
<div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160;        btensor A({{{2, cqt(0)}, {3, cqt(1)}},</div>
<div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;                   {{1, cqt(1)}, {2, cqt(0)}, {3, cqt(-1)}, {1, cqt(1)}},</div>
<div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160;                   {{3, cqt(0)}, {2, cqt(-2)}, {2, cqt(-1)}}},</div>
<div class="line"><a name="l00410"></a><span class="lineno">  410</span>&#160;                  selection_rule);</div>
<div class="line"><a name="l00411"></a><span class="lineno">  411</span>&#160;        A.block({0, 0, 2}) = tole * torch::rand({2, 1, 2});</div>
<div class="line"><a name="l00412"></a><span class="lineno">  412</span>&#160;        A.block({0, 1, 0}) = tole * torch::rand({2, 2, 3});</div>
<div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;        A.block({0, 3, 2}) = 0.1 * tole * torch::rand({2, 1, 2});</div>
<div class="line"><a name="l00414"></a><span class="lineno">  414</span>&#160;        A.block({1, 0, 1}) = tole * torch::rand({3, 1, 2});</div>
<div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160;        A.block({1, 1, 2}) = tole * torch::rand({3, 2, 2});</div>
<div class="line"><a name="l00416"></a><span class="lineno">  416</span>&#160;        A.block({1, 2, 0}) = 0.1 * tole * torch::rand({3, 3, 3});</div>
<div class="line"><a name="l00417"></a><span class="lineno">  417</span>&#160;        A.block({1, 3, 1}) = tole * torch::rand({3, 1, 2});</div>
<div class="line"><a name="l00418"></a><span class="lineno">  418</span>&#160;        <span class="comment">// fmt::print(&quot;A \n{}\n\n&quot;,A);</span></div>
<div class="line"><a name="l00419"></a><span class="lineno">  419</span>&#160;        qtt_REQUIRE_NOTHROW(<a class="code" href="classquantit_1_1btensor.html#a5d8897e8e51c880654c5d467b2b0a8bc">btensor::throw_bad_tensor</a>(A));</div>
<div class="line"><a name="l00420"></a><span class="lineno">  420</span>&#160;        qtt_SUBCASE(<span class="stringliteral">&quot;tensor singular decomposition&quot;</span>)</div>
<div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;        {</div>
<div class="line"><a name="l00422"></a><span class="lineno">  422</span>&#160;            btensor U, d, V;</div>
<div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;            qtt_REQUIRE_NOTHROW(std::tie(U, d, V) = svd(A, 1));</div>
<div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;            <span class="comment">// fmt::print(&quot;U \n{}\n\n&quot;,U);</span></div>
<div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;            <span class="comment">// fmt::print(&quot;d \n{}\n\n&quot;,d);</span></div>
<div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;            <span class="comment">// fmt::print(&quot;V \n{}\n\n&quot;,V);</span></div>
<div class="line"><a name="l00427"></a><span class="lineno">  427</span>&#160;            <span class="keyword">auto</span> Ud = U.mul(d);</div>
<div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160;            <span class="comment">// fmt::print(&quot;Ud \n{}\n\n&quot;,Ud);</span></div>
<div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;            <span class="keyword">auto</span> AA = tensordot(Ud, V.conj(), {U.dim() - 1}, {V.dim() - 1});</div>
<div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;            <span class="comment">// fmt::print(&quot;AA \n{}\n\n&quot;,AA);</span></div>
<div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;            <span class="keyword">auto</span> AA_it = AA.begin();</div>
<div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;            <span class="keyword">auto</span> A_it = A.begin();</div>
<div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;            qtt_REQUIRE(std::distance(AA_it, AA.end()) == std::distance(A_it, A.end()));</div>
<div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;            <span class="keywordflow">while</span> (AA_it != AA.end())</div>
<div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;            {</div>
<div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;                <span class="keyword">auto</span> AA_ind = std::get&lt;0&gt;(*AA_it);</div>
<div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;                <span class="keyword">auto</span> A_ind = std::get&lt;0&gt;(*A_it);</div>
<div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;                <span class="keyword">auto</span> AA_tens = std::get&lt;1&gt;(*AA_it);</div>
<div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;                <span class="keyword">auto</span> A_tens = std::get&lt;1&gt;(*A_it);</div>
<div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;                qtt_CHECK(AA_ind == A_ind);</div>
<div class="line"><a name="l00441"></a><span class="lineno">  441</span>&#160;                qtt_CHECK(torch::allclose(AA_tens, A_tens));</div>
<div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160;                ++AA_it;</div>
<div class="line"><a name="l00443"></a><span class="lineno">  443</span>&#160;                ++A_it;</div>
<div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160;            }</div>
<div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160;        }</div>
<div class="line"><a name="l00446"></a><span class="lineno">  446</span>&#160;        qtt_SUBCASE(<span class="stringliteral">&quot;random tensor decomposition&quot;</span>)</div>
<div class="line"><a name="l00447"></a><span class="lineno">  447</span>&#160;        {</div>
<div class="line"><a name="l00448"></a><span class="lineno">  448</span>&#160;            <span class="keyword">using</span> cqt = conserved::C&lt;2&gt;;</div>
<div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;            btensor dummy = rand({}, cqt(0));</div>
<div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;            btensor X = quantit::rand({{{2, cqt(-2)}, {2, cqt(0)}, {2, cqt(2)}},</div>
<div class="line"><a name="l00451"></a><span class="lineno">  451</span>&#160;                                      {{1, cqt(1)}, {1, cqt(-1)}},</div>
<div class="line"><a name="l00452"></a><span class="lineno">  452</span>&#160;                                      {{1, cqt(1)}, {1, cqt(-1)}},</div>
<div class="line"><a name="l00453"></a><span class="lineno">  453</span>&#160;                                      {{2, cqt(2)}, {2, cqt(0)}, {2, cqt(-2)}}},</div>
<div class="line"><a name="l00454"></a><span class="lineno">  454</span>&#160;                                     cqt(0));</div>
<div class="line"><a name="l00455"></a><span class="lineno">  455</span>&#160;            <span class="keyword">auto</span> [U, d, V] = svd(X, 2);</div>
<div class="line"><a name="l00456"></a><span class="lineno">  456</span>&#160;            qtt_CHECK(tensordot(U, U.conj(), {0, 1, 2}, {0, 1, 2}).<a class="code" href="classquantit_1_1btensor.html#a01c490238e0022b585dc430b13ec7dd1">item</a>().toDouble() == doctest::Approx(d.sizes()[0]));</div>
<div class="line"><a name="l00457"></a><span class="lineno">  457</span>&#160;            qtt_CHECK(tensordot(V, V.conj(), {0, 1, 2}, {0, 1, 2}).<a class="code" href="classquantit_1_1btensor.html#a01c490238e0022b585dc430b13ec7dd1">item</a>().toDouble() == doctest::Approx(d.sizes()[0]));</div>
<div class="line"><a name="l00458"></a><span class="lineno">  458</span>&#160;            qtt_CHECK(tensordot(U, U.conj(), {2, 0, 1}, {2, 0, 1}).<a class="code" href="classquantit_1_1btensor.html#a01c490238e0022b585dc430b13ec7dd1">item</a>().toDouble() == doctest::Approx(d.sizes()[0]));</div>
<div class="line"><a name="l00459"></a><span class="lineno">  459</span>&#160;            qtt_CHECK(tensordot(V, V.conj(), {2, 0, 1}, {2, 0, 1}).<a class="code" href="classquantit_1_1btensor.html#a01c490238e0022b585dc430b13ec7dd1">item</a>().toDouble() == doctest::Approx(d.sizes()[0]));</div>
<div class="line"><a name="l00460"></a><span class="lineno">  460</span>&#160;            <span class="comment">// fmt::print(&quot;U shape {}\n\nV shape {}\n\n d {}\n\n&quot;,shape_from(U,dummy),shape_from(V,dummy),d);</span></div>
<div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;            <span class="keyword">auto</span> U2 = U.reshape({2});</div>
<div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;            <span class="keyword">auto</span> V2 = V.reshape({2});</div>
<div class="line"><a name="l00463"></a><span class="lineno">  463</span>&#160;            <span class="comment">// fmt::print(&quot;U {}\n\nV {}\n\n&quot;, tensordot(U2,U2.conj(), {1,0},{1,0}),tensordot(V2,V2.conj(),{1,0},{1,0}));</span></div>
<div class="line"><a name="l00464"></a><span class="lineno">  464</span>&#160;            qtt_CHECK(allclose(tensordot(U.mul(d), V.conj(), {2}, {2}), X));</div>
<div class="line"><a name="l00465"></a><span class="lineno">  465</span>&#160;            <span class="comment">// auto XX = tensordot(U.mul(d), V.conj(), {2}, {2});</span></div>
<div class="line"><a name="l00466"></a><span class="lineno">  466</span>&#160;            <span class="comment">// fmt::print(&quot;X\n{}\n\n&quot;, shape_from(X, dummy));</span></div>
<div class="line"><a name="l00467"></a><span class="lineno">  467</span>&#160;            <span class="comment">// fmt::print(&quot;reconstituded X\n{}\n\n&quot;, shape_from(XX, dummy));</span></div>
<div class="line"><a name="l00468"></a><span class="lineno">  468</span>&#160;            <span class="comment">// fmt::print(&quot;U\n{}\n\n&quot;, shape_from(U, dummy));</span></div>
<div class="line"><a name="l00469"></a><span class="lineno">  469</span>&#160;            <span class="comment">// fmt::print(&quot;d\n{}\n\n&quot;, shape_from(d, dummy));</span></div>
<div class="line"><a name="l00470"></a><span class="lineno">  470</span>&#160;            <span class="comment">// fmt::print(&quot;V\n{}\n\n&quot;, shape_from(V, dummy));</span></div>
<div class="line"><a name="l00471"></a><span class="lineno">  471</span>&#160;        }</div>
<div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160;        qtt_SUBCASE(<span class="stringliteral">&quot;truncating tensor singular decomposition&quot;</span>)</div>
<div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;        {</div>
<div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;            btensor U, d, V;</div>
<div class="line"><a name="l00475"></a><span class="lineno">  475</span>&#160;            qtt_REQUIRE_NOTHROW(std::tie(U, d, V) = svd(A, 1, tole));</div>
<div class="line"><a name="l00476"></a><span class="lineno">  476</span>&#160;            <span class="comment">// fmt::print(&quot;U \n{}\n\n&quot;,U);</span></div>
<div class="line"><a name="l00477"></a><span class="lineno">  477</span>&#160;            <span class="comment">// fmt::print(&quot;d \n{}\n\n&quot;,d);</span></div>
<div class="line"><a name="l00478"></a><span class="lineno">  478</span>&#160;            <span class="comment">// fmt::print(&quot;V \n{}\n\n&quot;,V);</span></div>
<div class="line"><a name="l00479"></a><span class="lineno">  479</span>&#160;            <span class="keyword">auto</span> AA = tensordot(U.mul(d), V.conj(), {U.dim() - 1}, {V.dim() - 1});</div>
<div class="line"><a name="l00480"></a><span class="lineno">  480</span>&#160;            <span class="comment">// fmt::print(&quot;AA \n{}\n\n&quot;,AA);</span></div>
<div class="line"><a name="l00481"></a><span class="lineno">  481</span>&#160;            <span class="keyword">auto</span> AA_it = AA.begin();</div>
<div class="line"><a name="l00482"></a><span class="lineno">  482</span>&#160;            <span class="keyword">auto</span> A_it = A.begin();</div>
<div class="line"><a name="l00483"></a><span class="lineno">  483</span>&#160;            qtt_REQUIRE(std::distance(AA_it, AA.end()) &lt;= std::distance(A_it, A.end()));</div>
<div class="line"><a name="l00484"></a><span class="lineno">  484</span>&#160;            <span class="keywordflow">while</span> (AA_it != AA.end())</div>
<div class="line"><a name="l00485"></a><span class="lineno">  485</span>&#160;            {</div>
<div class="line"><a name="l00486"></a><span class="lineno">  486</span>&#160;                <span class="keyword">auto</span> AA_ind = std::get&lt;0&gt;(*AA_it);</div>
<div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160;                <span class="keyword">auto</span> A_ind = std::get&lt;0&gt;(*A_it);</div>
<div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;                <span class="keyword">auto</span> AA_tens = std::get&lt;1&gt;(*AA_it);</div>
<div class="line"><a name="l00489"></a><span class="lineno">  489</span>&#160;                <span class="keyword">auto</span> A_tens = std::get&lt;1&gt;(*A_it);</div>
<div class="line"><a name="l00490"></a><span class="lineno">  490</span>&#160;                <span class="keywordflow">if</span> (AA_ind == A_ind)</div>
<div class="line"><a name="l00491"></a><span class="lineno">  491</span>&#160;                {</div>
<div class="line"><a name="l00492"></a><span class="lineno">  492</span>&#160;                    qtt_CHECK(torch::all(torch::less(torch::abs(A_tens - AA_tens), tole)).item().to&lt;bool&gt;());</div>
<div class="line"><a name="l00493"></a><span class="lineno">  493</span>&#160;                    <span class="comment">// if (not torch::all(torch::less(torch::abs(A_tens-AA_tens),tol)).item().to&lt;bool&gt;())</span></div>
<div class="line"><a name="l00494"></a><span class="lineno">  494</span>&#160;                    <span class="comment">// {</span></div>
<div class="line"><a name="l00495"></a><span class="lineno">  495</span>&#160;                    <span class="comment">//  fmt::print(&quot;reduction check failed: ind {}\n&quot;,A_ind);</span></div>
<div class="line"><a name="l00496"></a><span class="lineno">  496</span>&#160;                    <span class="comment">//  fmt::print(&quot;absolute difference \n{}\n\n&quot;,torch::abs(A_tens-AA_tens));</span></div>
<div class="line"><a name="l00497"></a><span class="lineno">  497</span>&#160;                    <span class="comment">// }</span></div>
<div class="line"><a name="l00498"></a><span class="lineno">  498</span>&#160;                    <span class="comment">// qtt_CHECK(torch::allclose(AA_tens, A_tens, tol, tol));</span></div>
<div class="line"><a name="l00499"></a><span class="lineno">  499</span>&#160;                    ++AA_it;</div>
<div class="line"><a name="l00500"></a><span class="lineno">  500</span>&#160;                    ++A_it;</div>
<div class="line"><a name="l00501"></a><span class="lineno">  501</span>&#160;                }</div>
<div class="line"><a name="l00502"></a><span class="lineno">  502</span>&#160;                <span class="keywordflow">else</span></div>
<div class="line"><a name="l00503"></a><span class="lineno">  503</span>&#160;                {</div>
<div class="line"><a name="l00504"></a><span class="lineno">  504</span>&#160;                    <span class="comment">// if a block from A is literally not present in AA, then that block must be all zeros to the</span></div>
<div class="line"><a name="l00505"></a><span class="lineno">  505</span>&#160;                    <span class="comment">// tol.</span></div>
<div class="line"><a name="l00506"></a><span class="lineno">  506</span>&#160;                    qtt_CHECK(torch::all(torch::less(torch::abs(A_tens), tole)).item().to&lt;bool&gt;());</div>
<div class="line"><a name="l00507"></a><span class="lineno">  507</span>&#160;                    <span class="comment">// if (not torch::all(torch::less(torch::abs(A_tens),tol)).item().to&lt;bool&gt;())</span></div>
<div class="line"><a name="l00508"></a><span class="lineno">  508</span>&#160;                    <span class="comment">// {</span></div>
<div class="line"><a name="l00509"></a><span class="lineno">  509</span>&#160;                    <span class="comment">//  fmt::print(&quot;block removed check failed: ind {}\n&quot;,A_ind);</span></div>
<div class="line"><a name="l00510"></a><span class="lineno">  510</span>&#160;                    <span class="comment">//  fmt::print(&quot;a_tens \n{}\n\n&quot;,A_tens);</span></div>
<div class="line"><a name="l00511"></a><span class="lineno">  511</span>&#160;                    <span class="comment">// }</span></div>
<div class="line"><a name="l00512"></a><span class="lineno">  512</span>&#160;                    <span class="comment">// qtt_CHECK(torch::allclose(A_tens,torch::zeros_like(A_tens),tol,tol));</span></div>
<div class="line"><a name="l00513"></a><span class="lineno">  513</span>&#160;                    <span class="keywordtype">bool</span> AAlessA = AA_ind &lt; A_ind;</div>
<div class="line"><a name="l00514"></a><span class="lineno">  514</span>&#160;                    AA_it += AAlessA;</div>
<div class="line"><a name="l00515"></a><span class="lineno">  515</span>&#160;                    A_it += !AAlessA;</div>
<div class="line"><a name="l00516"></a><span class="lineno">  516</span>&#160;                }</div>
<div class="line"><a name="l00517"></a><span class="lineno">  517</span>&#160;            }</div>
<div class="line"><a name="l00518"></a><span class="lineno">  518</span>&#160;        }</div>
<div class="line"><a name="l00519"></a><span class="lineno">  519</span>&#160;        qtt_SUBCASE(<span class="stringliteral">&quot;truncating smaller tensor singular decomposition&quot;</span>)</div>
<div class="line"><a name="l00520"></a><span class="lineno">  520</span>&#160;        {</div>
<div class="line"><a name="l00521"></a><span class="lineno">  521</span>&#160;            btensor U, d, V;</div>
<div class="line"><a name="l00522"></a><span class="lineno">  522</span>&#160;            A.mul_(0.3);</div>
<div class="line"><a name="l00523"></a><span class="lineno">  523</span>&#160;            qtt_REQUIRE_NOTHROW(std::tie(U, d, V) = svd(A, 1, tole));</div>
<div class="line"><a name="l00524"></a><span class="lineno">  524</span>&#160;            <span class="comment">// fmt::print(&quot;U \n{}\n\n&quot;,U);</span></div>
<div class="line"><a name="l00525"></a><span class="lineno">  525</span>&#160;            <span class="comment">// fmt::print(&quot;d \n{}\n\n&quot;,d);</span></div>
<div class="line"><a name="l00526"></a><span class="lineno">  526</span>&#160;            <span class="comment">// fmt::print(&quot;V \n{}\n\n&quot;,V);</span></div>
<div class="line"><a name="l00527"></a><span class="lineno">  527</span>&#160;            <span class="keyword">auto</span> AA = tensordot(U.mul(d), V.conj(), {U.dim() - 1}, {V.dim() - 1});</div>
<div class="line"><a name="l00528"></a><span class="lineno">  528</span>&#160;            <span class="comment">// fmt::print(&quot;AA \n{}\n\n&quot;,AA);</span></div>
<div class="line"><a name="l00529"></a><span class="lineno">  529</span>&#160;            <span class="keyword">auto</span> AA_it = AA.begin();</div>
<div class="line"><a name="l00530"></a><span class="lineno">  530</span>&#160;            <span class="keyword">auto</span> A_it = A.begin();</div>
<div class="line"><a name="l00531"></a><span class="lineno">  531</span>&#160;            qtt_REQUIRE(std::distance(AA_it, AA.end()) &lt;= std::distance(A_it, A.end()));</div>
<div class="line"><a name="l00532"></a><span class="lineno">  532</span>&#160;            <span class="keywordflow">while</span> (AA_it != AA.end())</div>
<div class="line"><a name="l00533"></a><span class="lineno">  533</span>&#160;            {</div>
<div class="line"><a name="l00534"></a><span class="lineno">  534</span>&#160;                <span class="keyword">auto</span> AA_ind = std::get&lt;0&gt;(*AA_it);</div>
<div class="line"><a name="l00535"></a><span class="lineno">  535</span>&#160;                <span class="keyword">auto</span> A_ind = std::get&lt;0&gt;(*A_it);</div>
<div class="line"><a name="l00536"></a><span class="lineno">  536</span>&#160;                <span class="keyword">auto</span> AA_tens = std::get&lt;1&gt;(*AA_it);</div>
<div class="line"><a name="l00537"></a><span class="lineno">  537</span>&#160;                <span class="keyword">auto</span> A_tens = std::get&lt;1&gt;(*A_it);</div>
<div class="line"><a name="l00538"></a><span class="lineno">  538</span>&#160;                <span class="keywordflow">if</span> (AA_ind == A_ind)</div>
<div class="line"><a name="l00539"></a><span class="lineno">  539</span>&#160;                {</div>
<div class="line"><a name="l00540"></a><span class="lineno">  540</span>&#160;                    qtt_CHECK(torch::all(torch::less(torch::abs(A_tens - AA_tens), tole)).item().to&lt;bool&gt;());</div>
<div class="line"><a name="l00541"></a><span class="lineno">  541</span>&#160;                    <span class="comment">// if (not torch::all(torch::less(torch::abs(A_tens-AA_tens),tol)).item().to&lt;bool&gt;())</span></div>
<div class="line"><a name="l00542"></a><span class="lineno">  542</span>&#160;                    <span class="comment">// {</span></div>
<div class="line"><a name="l00543"></a><span class="lineno">  543</span>&#160;                    <span class="comment">//  fmt::print(&quot;reduction check failed: ind {}\n&quot;,A_ind);</span></div>
<div class="line"><a name="l00544"></a><span class="lineno">  544</span>&#160;                    <span class="comment">//  fmt::print(&quot;absolute difference \n{}\n\n&quot;,torch::abs(A_tens-AA_tens));</span></div>
<div class="line"><a name="l00545"></a><span class="lineno">  545</span>&#160;                    <span class="comment">// }</span></div>
<div class="line"><a name="l00546"></a><span class="lineno">  546</span>&#160;                    <span class="comment">// qtt_CHECK(torch::allclose(AA_tens, A_tens, tol, tol));</span></div>
<div class="line"><a name="l00547"></a><span class="lineno">  547</span>&#160;                    ++AA_it;</div>
<div class="line"><a name="l00548"></a><span class="lineno">  548</span>&#160;                    ++A_it;</div>
<div class="line"><a name="l00549"></a><span class="lineno">  549</span>&#160;                }</div>
<div class="line"><a name="l00550"></a><span class="lineno">  550</span>&#160;                <span class="keywordflow">else</span></div>
<div class="line"><a name="l00551"></a><span class="lineno">  551</span>&#160;                {</div>
<div class="line"><a name="l00552"></a><span class="lineno">  552</span>&#160;                    <span class="comment">// if a block from A is literally not present in AA, then that block must be all zeros to the</span></div>
<div class="line"><a name="l00553"></a><span class="lineno">  553</span>&#160;                    <span class="comment">// tol.</span></div>
<div class="line"><a name="l00554"></a><span class="lineno">  554</span>&#160;                    qtt_CHECK(torch::all(torch::less(torch::abs(A_tens), tole)).item().to&lt;bool&gt;());</div>
<div class="line"><a name="l00555"></a><span class="lineno">  555</span>&#160;                    <span class="comment">// if (not torch::all(torch::less(torch::abs(A_tens),tol)).item().to&lt;bool&gt;())</span></div>
<div class="line"><a name="l00556"></a><span class="lineno">  556</span>&#160;                    <span class="comment">// {</span></div>
<div class="line"><a name="l00557"></a><span class="lineno">  557</span>&#160;                    <span class="comment">//  fmt::print(&quot;block removed check failed: ind {}\n&quot;,A_ind);</span></div>
<div class="line"><a name="l00558"></a><span class="lineno">  558</span>&#160;                    <span class="comment">//  fmt::print(&quot;a_tens \n{}\n\n&quot;,A_tens);</span></div>
<div class="line"><a name="l00559"></a><span class="lineno">  559</span>&#160;                    <span class="comment">// }</span></div>
<div class="line"><a name="l00560"></a><span class="lineno">  560</span>&#160;                    <span class="comment">// qtt_CHECK(torch::allclose(A_tens,torch::zeros_like(A_tens),tol,tol));</span></div>
<div class="line"><a name="l00561"></a><span class="lineno">  561</span>&#160;                    <span class="keywordtype">bool</span> AAlessA = AA_ind &lt; A_ind;</div>
<div class="line"><a name="l00562"></a><span class="lineno">  562</span>&#160;                    AA_it += AAlessA;</div>
<div class="line"><a name="l00563"></a><span class="lineno">  563</span>&#160;                    A_it += !AAlessA;</div>
<div class="line"><a name="l00564"></a><span class="lineno">  564</span>&#160;                }</div>
<div class="line"><a name="l00565"></a><span class="lineno">  565</span>&#160;            }</div>
<div class="line"><a name="l00566"></a><span class="lineno">  566</span>&#160;        }</div>
<div class="line"><a name="l00567"></a><span class="lineno">  567</span>&#160;    }</div>
<div class="line"><a name="l00568"></a><span class="lineno">  568</span>&#160;}</div>
<div class="line"><a name="l00569"></a><span class="lineno">  569</span>&#160; </div>
<div class="line"><a name="l00570"></a><span class="lineno">  570</span>&#160;} <span class="comment">// namespace quantit</span></div>
<div class="line"><a name="l00571"></a><span class="lineno">  571</span>&#160; </div>
<div class="line"><a name="l00572"></a><span class="lineno">  572</span>&#160;<span class="preprocessor">#endif </span><span class="comment">// BTENSORLINEARALGEBRA_H</span></div>
<div class="ttc" id="aclassquantit_1_1btensor_html"><div class="ttname"><a href="classquantit_1_1btensor.html">quantit::btensor</a></div><div class="ttdoc">btensor is a type meant to represent block sparse tensor with conservation laws. The conservation law...</div><div class="ttdef"><b>Definition:</b> btensor.h:104</div></div>
<div class="ttc" id="aclassquantit_1_1btensor_html_a01c490238e0022b585dc430b13ec7dd1"><div class="ttname"><a href="classquantit_1_1btensor.html#a01c490238e0022b585dc430b13ec7dd1">quantit::btensor::item</a></div><div class="ttdeci">btensor::Scalar item() const</div><div class="ttdoc">if the tensor contain a single element, return a scalar object.</div></div>
<div class="ttc" id="aclassquantit_1_1btensor_html_a5d8897e8e51c880654c5d467b2b0a8bc"><div class="ttname"><a href="classquantit_1_1btensor.html#a5d8897e8e51c880654c5d467b2b0a8bc">quantit::btensor::throw_bad_tensor</a></div><div class="ttdeci">static void throw_bad_tensor(const btensor &amp;)</div><div class="ttdoc">throw an error in any situation where check_tensor return a non-empty string</div></div>
<div class="ttc" id="astructquantit_1_1BOOL_html"><div class="ttname"><a href="structquantit_1_1BOOL.html">quantit::BOOL</a></div><div class="ttdoc">A bool type with no implicit conversion from arithmetic types.</div><div class="ttdef"><b>Definition:</b> LinearAlgebra.h:31</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
