<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.3"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>QuantiT: /Users/alex/Documents/Prog/QuantiT/include/blockTensor/LinearAlgebra.h Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">QuantiT<span id="projectnumber">&#160;0.1</span>
   </div>
   <div id="projectbrief">A tensor network library for quantum mechanics</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.3 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="dir_7a13f9132e4f8cac71358e1544611c31.html">blockTensor</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle"><div class="title">LinearAlgebra.h</div></div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno">    1</span><span class="comment">/*</span></div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span><span class="comment"> * File: LinearAlgebra.h</span></div>
<div class="line"><a id="l00003" name="l00003"></a><span class="lineno">    3</span><span class="comment"> * Project: QuantiT</span></div>
<div class="line"><a id="l00004" name="l00004"></a><span class="lineno">    4</span><span class="comment"> * File Created: Thursday, 13th May 2021 11:22:38 am</span></div>
<div class="line"><a id="l00005" name="l00005"></a><span class="lineno">    5</span><span class="comment"> * Author: Alexandre Foley (Alexandre.foley@usherbrooke.ca)</span></div>
<div class="line"><a id="l00006" name="l00006"></a><span class="lineno">    6</span><span class="comment"> * Copyright (c) 2021 Alexandre Foley</span></div>
<div class="line"><a id="l00007" name="l00007"></a><span class="lineno">    7</span><span class="comment"> * Licensed under GPL v3</span></div>
<div class="line"><a id="l00008" name="l00008"></a><span class="lineno">    8</span><span class="comment"> */</span></div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span> </div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno">   10</span><span class="preprocessor">#ifndef BTENSORLINEARALGEBRA_H</span></div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span><span class="preprocessor">#define BTENSORLINEARALGEBRA_H</span></div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span> </div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno">   13</span><span class="preprocessor">#include &quot;blockTensor/btensor.h&quot;</span></div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno">   14</span><span class="preprocessor">#include &quot;doctest/doctest_proxy.h&quot;</span></div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span><span class="preprocessor">#include &lt;ATen/Functions.h&gt;</span></div>
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno">   16</span><span class="preprocessor">#include &lt;ATen/TensorIndexing.h&gt;</span></div>
<div class="line"><a id="l00017" name="l00017"></a><span class="lineno">   17</span><span class="preprocessor">#include &lt;fmt/core.h&gt;</span></div>
<div class="line"><a id="l00018" name="l00018"></a><span class="lineno">   18</span><span class="preprocessor">#include &lt;fmt/ranges.h&gt;</span></div>
<div class="line"><a id="l00019" name="l00019"></a><span class="lineno">   19</span><span class="preprocessor">#include &lt;ostream&gt;</span></div>
<div class="line"><a id="l00020" name="l00020"></a><span class="lineno">   20</span> </div>
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno">   21</span><span class="keyword">namespace </span>quantit</div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno">   22</span>{</div>
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno">   23</span> </div>
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno"><a class="line" href="structquantit_1_1BOOL.html">   30</a></span><span class="keyword">struct </span><a class="code hl_struct" href="structquantit_1_1BOOL.html">BOOL</a></div>
<div class="line"><a id="l00031" name="l00031"></a><span class="lineno">   31</span>{</div>
<div class="line"><a id="l00032" name="l00032"></a><span class="lineno">   32</span>    <span class="keywordtype">bool</span> val;</div>
<div class="line"><a id="l00033" name="l00033"></a><span class="lineno">   33</span>    <a class="code hl_struct" href="structquantit_1_1BOOL.html">BOOL</a>(<span class="keywordtype">bool</span> _val) noexcept : val(_val) {}</div>
<div class="line"><a id="l00034" name="l00034"></a><span class="lineno">   34</span>    <span class="keyword">operator</span> bool() <span class="keyword">const</span> <span class="keyword">noexcept</span> { <span class="keywordflow">return</span> val; }</div>
<div class="line"><a id="l00035" name="l00035"></a><span class="lineno">   35</span>};</div>
<div class="line"><a id="l00074" name="l00074"></a><span class="lineno">   74</span>std::tuple&lt;btensor, btensor, btensor&gt; svd(<span class="keyword">const</span> <a class="code hl_class" href="classquantit_1_1btensor.html">btensor</a> &amp;tensor, <a class="code hl_struct" href="structquantit_1_1BOOL.html">BOOL</a> some = <span class="keyword">true</span>, <a class="code hl_struct" href="structquantit_1_1BOOL.html">BOOL</a> compute_uv = <span class="keyword">true</span>);</div>
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno">   75</span> </div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span>std::tuple&lt;btensor, btensor, btensor&gt; svd(<span class="keyword">const</span> <a class="code hl_class" href="classquantit_1_1btensor.html">btensor</a> &amp;tensor, <span class="keywordtype">size_t</span> split);</div>
<div class="line"><a id="l00092" name="l00092"></a><span class="lineno">   92</span><span class="keyword">inline</span> std::tuple&lt;btensor, btensor, btensor&gt; svd(<span class="keyword">const</span> <a class="code hl_class" href="classquantit_1_1btensor.html">btensor</a> &amp;tensor, <span class="keywordtype">int</span> split)</div>
<div class="line"><a id="l00093" name="l00093"></a><span class="lineno">   93</span>{</div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno">   94</span>    <span class="keywordflow">return</span> svd(tensor, <span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(split));</div>
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno">   95</span>}</div>
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno">   96</span> </div>
<div class="line"><a id="l00115" name="l00115"></a><span class="lineno">  115</span>std::tuple&lt;btensor, btensor, btensor&gt; svd(<span class="keyword">const</span> btensor &amp;A, <span class="keywordtype">size_t</span> split, btensor::Scalar tol, <span class="keywordtype">size_t</span> min_size,</div>
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno">  116</span>                                          <span class="keywordtype">size_t</span> max_size, btensor::Scalar pow = 2);</div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno">  121</span><span class="keyword">inline</span> std::tuple&lt;btensor, btensor, btensor&gt; svd(<span class="keyword">const</span> btensor &amp;A, <span class="keywordtype">int</span> split, btensor::Scalar tol, <span class="keywordtype">size_t</span> min_size,</div>
<div class="line"><a id="l00122" name="l00122"></a><span class="lineno">  122</span>                                                 <span class="keywordtype">size_t</span> max_size, btensor::Scalar pow = 2)</div>
<div class="line"><a id="l00123" name="l00123"></a><span class="lineno">  123</span>{</div>
<div class="line"><a id="l00124" name="l00124"></a><span class="lineno">  124</span>    <span class="keywordflow">return</span> svd(A, <span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(split), tol, min_size, max_size, pow);</div>
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno">  125</span>}</div>
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno">  142</span>std::tuple&lt;btensor, btensor, btensor&gt; svd(<span class="keyword">const</span> btensor &amp;A, <span class="keywordtype">size_t</span> split, btensor::Scalar tol, btensor::Scalar pow = 2);</div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno">  146</span><span class="keyword">inline</span> std::tuple&lt;btensor, btensor, btensor&gt; svd(<span class="keyword">const</span> btensor &amp;A, <span class="keywordtype">int</span> split, btensor::Scalar tol,</div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno">  147</span>                                                 btensor::Scalar pow = 2)</div>
<div class="line"><a id="l00148" name="l00148"></a><span class="lineno">  148</span>{</div>
<div class="line"><a id="l00149" name="l00149"></a><span class="lineno">  149</span>    <span class="keywordflow">return</span> svd(A, <span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(split), tol, pow);</div>
<div class="line"><a id="l00150" name="l00150"></a><span class="lineno">  150</span>}</div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno">  159</span>std::tuple&lt;btensor, btensor&gt; eigh(<span class="keyword">const</span> btensor &amp;tensor, BOOL upper = <span class="keyword">false</span>);</div>
<div class="line"><a id="l00167" name="l00167"></a><span class="lineno">  167</span>std::tuple&lt;btensor, btensor&gt; eigh(<span class="keyword">const</span> btensor &amp;tensor, <span class="keywordtype">size_t</span> split);</div>
<div class="line"><a id="l00180" name="l00180"></a><span class="lineno">  180</span>std::tuple&lt;btensor, btensor&gt; eigh(<span class="keyword">const</span> btensor &amp;A, <span class="keywordtype">size_t</span> split, btensor::Scalar tol, <span class="keywordtype">size_t</span> min_size,</div>
<div class="line"><a id="l00181" name="l00181"></a><span class="lineno">  181</span>                                    <span class="keywordtype">size_t</span> max_size, btensor::Scalar pow = 1);</div>
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno">  192</span>std::tuple&lt;btensor, btensor&gt; eigh(<span class="keyword">const</span> btensor &amp;A, <span class="keywordtype">size_t</span> split, btensor::Scalar tol, btensor::Scalar pow = 1);</div>
<div class="line"><a id="l00193" name="l00193"></a><span class="lineno">  193</span> </div>
<div class="line"><a id="l00194" name="l00194"></a><span class="lineno">  194</span><span class="keyword">namespace </span>LA_helpers</div>
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno">  195</span>{</div>
<div class="line"><a id="l00208" name="l00208"></a><span class="lineno">  208</span>btensor::block_list_t::content_t reorder_by_cvals(<span class="keyword">const</span> btensor &amp;tensor);</div>
<div class="line"><a id="l00209" name="l00209"></a><span class="lineno">  209</span> </div>
<div class="line"><a id="l00220" name="l00220"></a><span class="lineno">  220</span>std::tuple&lt;torch::Tensor, btensor::index_list, std::vector&lt;std::tuple&lt;int, torch::indexing::Slice&gt;&gt;,</div>
<div class="line"><a id="l00221" name="l00221"></a><span class="lineno">  221</span>           std::vector&lt;std::tuple&lt;int, torch::indexing::Slice&gt;&gt;&gt;</div>
<div class="line"><a id="l00222" name="l00222"></a><span class="lineno">  222</span>compact_dense_single(<span class="keyword">typename</span> btensor::block_list_t::content_t::const_iterator start,</div>
<div class="line"><a id="l00223" name="l00223"></a><span class="lineno">  223</span>                     <span class="keyword">typename</span> btensor::block_list_t::content_t::const_iterator end);</div>
<div class="line"><a id="l00224" name="l00224"></a><span class="lineno">  224</span> </div>
<div class="line"><a id="l00225" name="l00225"></a><span class="lineno">  225</span><span class="keyword">using</span> Slice = torch::indexing::Slice;</div>
<div class="line"><a id="l00226" name="l00226"></a><span class="lineno">  226</span><span class="keyword">using</span> TensInd = torch::indexing::TensorIndex;</div>
<div class="line"><a id="l00227" name="l00227"></a><span class="lineno">  227</span>std::tuple&lt;btensor::index_list, std::array&lt;TensInd, 3&gt;&gt; build_index_slice(<span class="keyword">const</span> btensor::index_list &amp;other_indices,</div>
<div class="line"><a id="l00228" name="l00228"></a><span class="lineno">  228</span>                                                                          <span class="keyword">const</span> std::tuple&lt;int, Slice&gt; &amp;rb_slices,</div>
<div class="line"><a id="l00229" name="l00229"></a><span class="lineno">  229</span>                                                                          <span class="keyword">const</span> std::tuple&lt;int, Slice&gt; &amp;cb_slices);</div>
<div class="line"><a id="l00230" name="l00230"></a><span class="lineno">  230</span> </div>
<div class="line"><a id="l00231" name="l00231"></a><span class="lineno">  231</span>std::vector&lt;std::tuple&lt;torch::Tensor, btensor::index_list, std::vector&lt;std::tuple&lt;int, torch::indexing::Slice&gt;&gt;,</div>
<div class="line"><a id="l00232" name="l00232"></a><span class="lineno">  232</span>                       std::vector&lt;std::tuple&lt;int, torch::indexing::Slice&gt;&gt;&gt;&gt;</div>
<div class="line"><a id="l00233" name="l00233"></a><span class="lineno">  233</span>compact_dense(<span class="keyword">const</span> btensor &amp;tensor);</div>
<div class="line"><a id="l00234" name="l00234"></a><span class="lineno">  234</span>} <span class="comment">// namespace LA_helpers</span></div>
<div class="line"><a id="l00235" name="l00235"></a><span class="lineno">  235</span> </div>
<div class="line"><a id="l00236" name="l00236"></a><span class="lineno">  236</span><span class="keyword">inline</span> std::ostream &amp;operator&lt;&lt;(std::ostream &amp;out, any_quantity_cref qt)</div>
<div class="line"><a id="l00237" name="l00237"></a><span class="lineno">  237</span>{</div>
<div class="line"><a id="l00238" name="l00238"></a><span class="lineno">  238</span>    out &lt;&lt; fmt::format(<span class="stringliteral">&quot;{}&quot;</span>, qt);</div>
<div class="line"><a id="l00239" name="l00239"></a><span class="lineno">  239</span>    <span class="keywordflow">return</span> out;</div>
<div class="line"><a id="l00240" name="l00240"></a><span class="lineno">  240</span>}</div>
<div class="line"><a id="l00241" name="l00241"></a><span class="lineno">  241</span> </div>
<div class="line"><a id="l00242" name="l00242"></a><span class="lineno">  242</span>std::string qformat(any_quantity_cref qt);</div>
<div class="line"><a id="l00243" name="l00243"></a><span class="lineno">  243</span> </div>
<div class="line"><a id="l00244" name="l00244"></a><span class="lineno">  244</span>std::tuple&lt;btensor, btensor&gt; truncate(btensor &amp;&amp;e, btensor &amp;&amp;S, <span class="keywordtype">size_t</span> max, <span class="keywordtype">size_t</span> min,</div>
<div class="line"><a id="l00245" name="l00245"></a><span class="lineno">  245</span>                                               btensor::Scalar tol, btensor::Scalar pow);</div>
<div class="line"><a id="l00246" name="l00246"></a><span class="lineno">  246</span>std::tuple&lt;btensor, btensor, btensor&gt; truncate(btensor &amp;&amp;U, btensor &amp;&amp;d, btensor &amp;&amp;V, <span class="keywordtype">size_t</span> max, <span class="keywordtype">size_t</span> min,</div>
<div class="line"><a id="l00247" name="l00247"></a><span class="lineno">  247</span>                                               btensor::Scalar tol, btensor::Scalar pow);</div>
<div class="line"><a id="l00248" name="l00248"></a><span class="lineno">  248</span> </div>
<div class="line"><a id="l00249" name="l00249"></a><span class="lineno">  249</span>qtt_TEST_CASE(<span class="stringliteral">&quot;btensor Linear algebra&quot;</span>)</div>
<div class="line"><a id="l00250" name="l00250"></a><span class="lineno">  250</span>{</div>
<div class="line"><a id="l00251" name="l00251"></a><span class="lineno">  251</span>    qtt_SUBCASE(<span class="stringliteral">&quot;decompositions&quot;</span>)</div>
<div class="line"><a id="l00252" name="l00252"></a><span class="lineno">  252</span>    {</div>
<div class="line"><a id="l00253" name="l00253"></a><span class="lineno">  253</span>        <span class="keyword">using</span> cqt = conserved::C&lt;5&gt;;</div>
<div class="line"><a id="l00254" name="l00254"></a><span class="lineno">  254</span>        <span class="keyword">using</span> index = btensor::index_list;</div>
<div class="line"><a id="l00255" name="l00255"></a><span class="lineno">  255</span>        any_quantity selection_rule(cqt(0)); <span class="comment">// DMRJulia flux</span></div>
<div class="line"><a id="l00256" name="l00256"></a><span class="lineno">  256</span>        btensor A({{{2, cqt(0)}, {3, cqt(1)}},</div>
<div class="line"><a id="l00257" name="l00257"></a><span class="lineno">  257</span>                   {{1, cqt(1)}, {2, cqt(0)}, {3, cqt(-1)}, {1, cqt(1)}},</div>
<div class="line"><a id="l00258" name="l00258"></a><span class="lineno">  258</span>                   {{3, cqt(0)}, {2, cqt(-2)}, {2, cqt(-1)}}},</div>
<div class="line"><a id="l00259" name="l00259"></a><span class="lineno">  259</span>                  selection_rule);</div>
<div class="line"><a id="l00260" name="l00260"></a><span class="lineno">  260</span>        A.block({0, 0, 2}) = torch::rand({2, 1, 2});</div>
<div class="line"><a id="l00261" name="l00261"></a><span class="lineno">  261</span>        A.block({0, 1, 0}) = torch::rand({2, 2, 3});</div>
<div class="line"><a id="l00262" name="l00262"></a><span class="lineno">  262</span>        A.block({0, 3, 2}) = torch::rand({2, 1, 2});</div>
<div class="line"><a id="l00263" name="l00263"></a><span class="lineno">  263</span>        A.block({1, 0, 1}) = torch::rand({3, 1, 2});</div>
<div class="line"><a id="l00264" name="l00264"></a><span class="lineno">  264</span>        A.block({1, 1, 2}) = torch::rand({3, 2, 2});</div>
<div class="line"><a id="l00265" name="l00265"></a><span class="lineno">  265</span>        A.block({1, 2, 0}) = torch::rand({3, 3, 3});</div>
<div class="line"><a id="l00266" name="l00266"></a><span class="lineno">  266</span>        A.block({1, 3, 1}) = torch::rand({3, 1, 2});</div>
<div class="line"><a id="l00267" name="l00267"></a><span class="lineno">  267</span>        qtt_REQUIRE_NOTHROW(<a class="code hl_function" href="classquantit_1_1btensor.html#a5d8897e8e51c880654c5d467b2b0a8bc">btensor::throw_bad_tensor</a>(A));</div>
<div class="line"><a id="l00268" name="l00268"></a><span class="lineno">  268</span>        btensor U,d,V;</div>
<div class="line"><a id="l00269" name="l00269"></a><span class="lineno">  269</span>        qtt_REQUIRE_NOTHROW( std::tie(U, d, V) = svd(A));</div>
<div class="line"><a id="l00270" name="l00270"></a><span class="lineno">  270</span><span class="preprocessor">#ifndef NDEBUG</span></div>
<div class="line"><a id="l00271" name="l00271"></a><span class="lineno">  271</span>        <span class="comment">// those helpers are not in the header when not in debug mode.</span></div>
<div class="line"><a id="l00272" name="l00272"></a><span class="lineno">  272</span>        qtt_SUBCASE(<span class="stringliteral">&quot;btensor linear algebra helpers&quot;</span>)</div>
<div class="line"><a id="l00273" name="l00273"></a><span class="lineno">  273</span>        {</div>
<div class="line"><a id="l00274" name="l00274"></a><span class="lineno">  274</span>            {</div>
<div class="line"><a id="l00275" name="l00275"></a><span class="lineno">  275</span>                <span class="keyword">auto</span> reordered_block = LA_helpers::reorder_by_cvals(A);</div>
<div class="line"><a id="l00276" name="l00276"></a><span class="lineno">  276</span>                std::vector&lt;btensor::index_list&gt; exp_blocks = {{0, 1, 0}, {1, 1, 2}, {1, 0, 1}, {1, 3, 1},</div>
<div class="line"><a id="l00277" name="l00277"></a><span class="lineno">  277</span>                                                               {0, 0, 2}, {0, 3, 2}, {1, 2, 0}};</div>
<div class="line"><a id="l00278" name="l00278"></a><span class="lineno">  278</span>                qtt_CHECK(exp_blocks.size() == reordered_block.size());</div>
<div class="line"><a id="l00279" name="l00279"></a><span class="lineno">  279</span>                <span class="keywordflow">for</span> (<span class="keyword">auto</span> [block, expec] = std::make_tuple(reordered_block.begin(), exp_blocks.begin());</div>
<div class="line"><a id="l00280" name="l00280"></a><span class="lineno">  280</span>                     block != reordered_block.end(); ++block, ++expec)</div>
<div class="line"><a id="l00281" name="l00281"></a><span class="lineno">  281</span>                {</div>
<div class="line"><a id="l00282" name="l00282"></a><span class="lineno">  282</span>                    <span class="comment">// auto cvals_view = A.block_quantities(std::get&lt;0&gt;(*block));</span></div>
<div class="line"><a id="l00283" name="l00283"></a><span class="lineno">  283</span>                    <span class="comment">// fmt::print( &quot;cvals: {}\n&quot;,fmt::join(cvals_view.begin(),cvals_view.end(),&quot;,&quot;));</span></div>
<div class="line"><a id="l00284" name="l00284"></a><span class="lineno">  284</span>                    <span class="comment">// fmt::print(&quot;block index: {}\n&quot;, std::get&lt;0&gt;(*block));</span></div>
<div class="line"><a id="l00285" name="l00285"></a><span class="lineno">  285</span>                    qtt_CHECK(std::get&lt;0&gt;(*block) == *expec);</div>
<div class="line"><a id="l00286" name="l00286"></a><span class="lineno">  286</span>                }</div>
<div class="line"><a id="l00287" name="l00287"></a><span class="lineno">  287</span>                <span class="comment">// reordered_block[2:4] is a set of block with the same c_vals on the last two indices, and with the</span></div>
<div class="line"><a id="l00288" name="l00288"></a><span class="lineno">  288</span>                <span class="comment">// same block indices for all but the last two dims.</span></div>
<div class="line"><a id="l00289" name="l00289"></a><span class="lineno">  289</span>                <span class="keyword">auto</span> [compact_tensor, other_indices, row_block_slices, col_block_slices] =</div>
<div class="line"><a id="l00290" name="l00290"></a><span class="lineno">  290</span>                    LA_helpers::compact_dense_single(reordered_block.begin() + 2, reordered_block.begin() + 4);</div>
<div class="line"><a id="l00291" name="l00291"></a><span class="lineno">  291</span>                qtt_REQUIRE(other_indices.size() == 1);</div>
<div class="line"><a id="l00292" name="l00292"></a><span class="lineno">  292</span>                <span class="keywordflow">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span> &amp;rb_slices : row_block_slices)</div>
<div class="line"><a id="l00293" name="l00293"></a><span class="lineno">  293</span>                {</div>
<div class="line"><a id="l00294" name="l00294"></a><span class="lineno">  294</span>                    <span class="keywordflow">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span> &amp;cb_slices : col_block_slices)</div>
<div class="line"><a id="l00295" name="l00295"></a><span class="lineno">  295</span>                    {</div>
<div class="line"><a id="l00296" name="l00296"></a><span class="lineno">  296</span>                        <span class="keyword">auto</span> [block_ind, slice] = LA_helpers::build_index_slice(other_indices, rb_slices, cb_slices);</div>
<div class="line"><a id="l00297" name="l00297"></a><span class="lineno">  297</span>                        <span class="comment">// we have rebuilt the block index in block_ind. It would be good to have a function to do that.</span></div>
<div class="line"><a id="l00298" name="l00298"></a><span class="lineno">  298</span>                        qtt_CHECK(torch::equal(A.block(block_ind), compact_tensor.index(slice)));</div>
<div class="line"><a id="l00299" name="l00299"></a><span class="lineno">  299</span>                        <span class="comment">// then we verify that the blocks from the original tensor can be obtained from the stored</span></div>
<div class="line"><a id="l00300" name="l00300"></a><span class="lineno">  300</span>                        <span class="comment">// slincing of the compacted tensor</span></div>
<div class="line"><a id="l00301" name="l00301"></a><span class="lineno">  301</span>                    }</div>
<div class="line"><a id="l00302" name="l00302"></a><span class="lineno">  302</span>                }</div>
<div class="line"><a id="l00303" name="l00303"></a><span class="lineno">  303</span>            }</div>
<div class="line"><a id="l00304" name="l00304"></a><span class="lineno">  304</span>            {</div>
<div class="line"><a id="l00305" name="l00305"></a><span class="lineno">  305</span>                btensor B;</div>
<div class="line"><a id="l00306" name="l00306"></a><span class="lineno">  306</span>                qtt_REQUIRE_NOTHROW(B = A.reshape({1})); <span class="comment">// joins dimensions 2 and 1</span></div>
<div class="line"><a id="l00307" name="l00307"></a><span class="lineno">  307</span>                <span class="comment">// fmt::print(&quot;tensor {}\n&quot;,B);</span></div>
<div class="line"><a id="l00308" name="l00308"></a><span class="lineno">  308</span>                <span class="keyword">auto</span> reordered_block = LA_helpers::reorder_by_cvals(B);</div>
<div class="line"><a id="l00309" name="l00309"></a><span class="lineno">  309</span>                std::vector&lt;btensor::index_list&gt; exp_blocks = {{0, 2}, {0, 3}, {0, 11}, {1, 1},</div>
<div class="line"><a id="l00310" name="l00310"></a><span class="lineno">  310</span>                                                               {1, 5}, {1, 6}, {1, 10}};</div>
<div class="line"><a id="l00311" name="l00311"></a><span class="lineno">  311</span>                qtt_CHECK(exp_blocks.size() == reordered_block.size());</div>
<div class="line"><a id="l00312" name="l00312"></a><span class="lineno">  312</span>                <span class="keywordflow">for</span> (<span class="keyword">auto</span> [block, expec] = std::make_tuple(reordered_block.begin(), exp_blocks.begin());</div>
<div class="line"><a id="l00313" name="l00313"></a><span class="lineno">  313</span>                     block != reordered_block.end(); ++block, ++expec)</div>
<div class="line"><a id="l00314" name="l00314"></a><span class="lineno">  314</span>                {</div>
<div class="line"><a id="l00315" name="l00315"></a><span class="lineno">  315</span>                    <span class="comment">// auto cvals_view = B.block_quantities(std::get&lt;0&gt;(*block));</span></div>
<div class="line"><a id="l00316" name="l00316"></a><span class="lineno">  316</span>                    <span class="comment">// fmt::print( &quot;cvals: {}\n&quot;,fmt::join(cvals_view.begin(),cvals_view.end(),&quot;,&quot;));</span></div>
<div class="line"><a id="l00317" name="l00317"></a><span class="lineno">  317</span>                    <span class="comment">// fmt::print(&quot;block index: {}\n&quot;, std::get&lt;0&gt;(*block));</span></div>
<div class="line"><a id="l00318" name="l00318"></a><span class="lineno">  318</span>                    qtt_CHECK(std::get&lt;0&gt;(*block) == *expec);</div>
<div class="line"><a id="l00319" name="l00319"></a><span class="lineno">  319</span>                }</div>
<div class="line"><a id="l00320" name="l00320"></a><span class="lineno">  320</span>                <span class="keyword">auto</span> [compact_tensor, other_indices, row_block_slices, col_block_slices] =</div>
<div class="line"><a id="l00321" name="l00321"></a><span class="lineno">  321</span>                    LA_helpers::compact_dense_single(reordered_block.begin(), reordered_block.begin() + 3);</div>
<div class="line"><a id="l00322" name="l00322"></a><span class="lineno">  322</span>                qtt_REQUIRE(other_indices.size() == 0);</div>
<div class="line"><a id="l00323" name="l00323"></a><span class="lineno">  323</span>                <span class="keywordflow">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span> &amp;rb_slices : row_block_slices)</div>
<div class="line"><a id="l00324" name="l00324"></a><span class="lineno">  324</span>                {</div>
<div class="line"><a id="l00325" name="l00325"></a><span class="lineno">  325</span>                    <span class="keywordflow">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span> &amp;cb_slices : col_block_slices)</div>
<div class="line"><a id="l00326" name="l00326"></a><span class="lineno">  326</span>                    {</div>
<div class="line"><a id="l00327" name="l00327"></a><span class="lineno">  327</span>                        <span class="keyword">auto</span> [block_ind, slice] = LA_helpers::build_index_slice(other_indices, rb_slices, cb_slices);</div>
<div class="line"><a id="l00328" name="l00328"></a><span class="lineno">  328</span>                        <span class="comment">// fmt::print(&quot;block {}, cval {}\n&quot;,block_ind,B.block_quantities(block_ind));</span></div>
<div class="line"><a id="l00329" name="l00329"></a><span class="lineno">  329</span>                        qtt_CHECK(torch::equal(B.block(block_ind), compact_tensor.index(slice)));</div>
<div class="line"><a id="l00330" name="l00330"></a><span class="lineno">  330</span>                        <span class="comment">// then we verify that the blocks from the original tensor can be obtained from the stored</span></div>
<div class="line"><a id="l00331" name="l00331"></a><span class="lineno">  331</span>                        <span class="comment">// slincing of the compacted tensor</span></div>
<div class="line"><a id="l00332" name="l00332"></a><span class="lineno">  332</span>                    }</div>
<div class="line"><a id="l00333" name="l00333"></a><span class="lineno">  333</span>                }</div>
<div class="line"><a id="l00334" name="l00334"></a><span class="lineno">  334</span>            }</div>
<div class="line"><a id="l00335" name="l00335"></a><span class="lineno">  335</span>        }</div>
<div class="line"><a id="l00336" name="l00336"></a><span class="lineno">  336</span><span class="preprocessor">#endif </span><span class="comment">// NDEBUG</span></div>
<div class="line"><a id="l00337" name="l00337"></a><span class="lineno">  337</span>       <span class="comment">// fmt::print(&quot;V {}\n&quot;,V);</span></div>
<div class="line"><a id="l00338" name="l00338"></a><span class="lineno">  338</span>        qtt_CHECK_NOTHROW(<a class="code hl_function" href="classquantit_1_1btensor.html#a5d8897e8e51c880654c5d467b2b0a8bc">btensor::throw_bad_tensor</a>(U));</div>
<div class="line"><a id="l00339" name="l00339"></a><span class="lineno">  339</span>        qtt_CHECK_NOTHROW(<a class="code hl_function" href="classquantit_1_1btensor.html#a5d8897e8e51c880654c5d467b2b0a8bc">btensor::throw_bad_tensor</a>(d));</div>
<div class="line"><a id="l00340" name="l00340"></a><span class="lineno">  340</span>        qtt_REQUIRE_NOTHROW(<a class="code hl_function" href="classquantit_1_1btensor.html#a5d8897e8e51c880654c5d467b2b0a8bc">btensor::throw_bad_tensor</a>(V));</div>
<div class="line"><a id="l00341" name="l00341"></a><span class="lineno">  341</span>        <span class="keyword">auto</span> d_r =</div>
<div class="line"><a id="l00342" name="l00342"></a><span class="lineno">  342</span>            d.reshape_as(shape_from(d, btensor({{{1, d.selection_rule-&gt;neutral()}}}, d.selection_rule-&gt;neutral())))</div>
<div class="line"><a id="l00343" name="l00343"></a><span class="lineno">  343</span>                .transpose_(-1, -2);</div>
<div class="line"><a id="l00344" name="l00344"></a><span class="lineno">  344</span>        <span class="keyword">auto</span> Vt = V.transpose(-1, -2).conj();</div>
<div class="line"><a id="l00345" name="l00345"></a><span class="lineno">  345</span>        <span class="keyword">auto</span> AA = U.mul(d_r).bmm(Vt);</div>
<div class="line"><a id="l00346" name="l00346"></a><span class="lineno">  346</span>        <span class="comment">// fmt::print(&quot;U {}\n&quot;,U);</span></div>
<div class="line"><a id="l00347" name="l00347"></a><span class="lineno">  347</span>        <span class="comment">// fmt::print(&quot;V {}\n&quot;,V);</span></div>
<div class="line"><a id="l00348" name="l00348"></a><span class="lineno">  348</span>        <span class="keyword">auto</span> it_AA = AA.begin();</div>
<div class="line"><a id="l00349" name="l00349"></a><span class="lineno">  349</span>        <span class="keyword">auto</span> it_A = A.begin();</div>
<div class="line"><a id="l00350" name="l00350"></a><span class="lineno">  350</span>        qtt_REQUIRE(std::distance(it_AA, AA.end()) == std::distance(it_A, A.end()));</div>
<div class="line"><a id="l00351" name="l00351"></a><span class="lineno">  351</span>        <span class="keywordflow">for</span> (; it_AA != AA.end(); ++it_AA, ++it_A)</div>
<div class="line"><a id="l00352" name="l00352"></a><span class="lineno">  352</span>        {</div>
<div class="line"><a id="l00353" name="l00353"></a><span class="lineno">  353</span>            <span class="keyword">auto</span> &amp;AA_ind = std::get&lt;0&gt;(*it_AA);</div>
<div class="line"><a id="l00354" name="l00354"></a><span class="lineno">  354</span>            <span class="keyword">auto</span> &amp;A_ind = std::get&lt;0&gt;(*it_A);</div>
<div class="line"><a id="l00355" name="l00355"></a><span class="lineno">  355</span>            <span class="keyword">auto</span> &amp;AA_tens = std::get&lt;1&gt;(*it_AA);</div>
<div class="line"><a id="l00356" name="l00356"></a><span class="lineno">  356</span>            <span class="keyword">auto</span> &amp;A_tens = std::get&lt;1&gt;(*it_A);</div>
<div class="line"><a id="l00357" name="l00357"></a><span class="lineno">  357</span>            qtt_CHECK(AA_ind == A_ind);</div>
<div class="line"><a id="l00358" name="l00358"></a><span class="lineno">  358</span>            qtt_CHECK(torch::allclose(AA_tens, A_tens));</div>
<div class="line"><a id="l00359" name="l00359"></a><span class="lineno">  359</span>        }</div>
<div class="line"><a id="l00360" name="l00360"></a><span class="lineno">  360</span>        <span class="keyword">auto</span> Ut = U.transpose(-2, -1).conj();</div>
<div class="line"><a id="l00361" name="l00361"></a><span class="lineno">  361</span>        <span class="comment">// fmt::print(&quot;Ut {}\n&quot;,Ut );</span></div>
<div class="line"><a id="l00362" name="l00362"></a><span class="lineno">  362</span>        <span class="comment">// fmt::print(&quot;U {}\n&quot;, U);</span></div>
<div class="line"><a id="l00363" name="l00363"></a><span class="lineno">  363</span>        <span class="keyword">auto</span> ID_u = U.bmm(Ut); <span class="comment">// ATTN! In general, Ut.bmm(Ut) != identity</span></div>
<div class="line"><a id="l00364" name="l00364"></a><span class="lineno">  364</span>        <span class="keyword">auto</span> ID_v = Vt.bmm(V); <span class="comment">// ATTN! In general, V.bmm(Vt) != Identity</span></div>
<div class="line"><a id="l00365" name="l00365"></a><span class="lineno">  365</span>        <span class="comment">// fmt::print(&quot;ID_U {}&quot;, ID_u);</span></div>
<div class="line"><a id="l00366" name="l00366"></a><span class="lineno">  366</span>        <span class="keywordflow">for</span> (<span class="keyword">auto</span> &amp;block : ID_u)</div>
<div class="line"><a id="l00367" name="l00367"></a><span class="lineno">  367</span>        {</div>
<div class="line"><a id="l00368" name="l00368"></a><span class="lineno">  368</span>            <span class="keyword">auto</span> &amp;ind = std::get&lt;0&gt;(block);</div>
<div class="line"><a id="l00369" name="l00369"></a><span class="lineno">  369</span>            <span class="keyword">auto</span> &amp;tens = std::get&lt;1&gt;(block);</div>
<div class="line"><a id="l00370" name="l00370"></a><span class="lineno">  370</span>            <span class="keywordflow">if</span> (ind[ind.size() - 1] == ind[ind.size() - 2])</div>
<div class="line"><a id="l00371" name="l00371"></a><span class="lineno">  371</span>            {</div>
<div class="line"><a id="l00372" name="l00372"></a><span class="lineno">  372</span>                qtt_CHECK(tens.sizes()[tens.dim() - 1] == tens.sizes()[tens.dim() - 2]);</div>
<div class="line"><a id="l00373" name="l00373"></a><span class="lineno">  373</span>                <span class="keyword">auto</span> <span class="keywordtype">id</span> = torch::eye(tens.sizes()[tens.dim() - 1]);</div>
<div class="line"><a id="l00374" name="l00374"></a><span class="lineno">  374</span>                qtt_CHECK(torch::allclose(<span class="keywordtype">id</span>, tens));</div>
<div class="line"><a id="l00375" name="l00375"></a><span class="lineno">  375</span>            }</div>
<div class="line"><a id="l00376" name="l00376"></a><span class="lineno">  376</span>            <span class="keywordflow">else</span></div>
<div class="line"><a id="l00377" name="l00377"></a><span class="lineno">  377</span>            {</div>
<div class="line"><a id="l00378" name="l00378"></a><span class="lineno">  378</span>                <span class="keyword">auto</span> zer = torch::zeros({tens.sizes()[tens.dim() - 2], tens.sizes()[tens.dim() - 1]});</div>
<div class="line"><a id="l00379" name="l00379"></a><span class="lineno">  379</span>                qtt_CHECK(torch::allclose(zer, tens));</div>
<div class="line"><a id="l00380" name="l00380"></a><span class="lineno">  380</span>            }</div>
<div class="line"><a id="l00381" name="l00381"></a><span class="lineno">  381</span>        }</div>
<div class="line"><a id="l00382" name="l00382"></a><span class="lineno">  382</span>        <span class="comment">// fmt::print(&quot;ID_V \n{}\n\n&quot;,ID_v);</span></div>
<div class="line"><a id="l00383" name="l00383"></a><span class="lineno">  383</span>        <span class="comment">// fmt::print(&quot;Vt \n{}\n\n&quot;,Vt);</span></div>
<div class="line"><a id="l00384" name="l00384"></a><span class="lineno">  384</span>        <span class="comment">// fmt::print(&quot;V \n{}\n\n&quot;,V);</span></div>
<div class="line"><a id="l00385" name="l00385"></a><span class="lineno">  385</span>        <span class="keywordflow">for</span> (<span class="keyword">auto</span> &amp;block : ID_v)</div>
<div class="line"><a id="l00386" name="l00386"></a><span class="lineno">  386</span>        {</div>
<div class="line"><a id="l00387" name="l00387"></a><span class="lineno">  387</span>            <span class="keyword">auto</span> &amp;ind = std::get&lt;0&gt;(block);</div>
<div class="line"><a id="l00388" name="l00388"></a><span class="lineno">  388</span>            <span class="keyword">auto</span> &amp;tens = std::get&lt;1&gt;(block);</div>
<div class="line"><a id="l00389" name="l00389"></a><span class="lineno">  389</span>            <span class="keywordflow">if</span> (ind[ind.size() - 1] == ind[ind.size() - 2])</div>
<div class="line"><a id="l00390" name="l00390"></a><span class="lineno">  390</span>            {</div>
<div class="line"><a id="l00391" name="l00391"></a><span class="lineno">  391</span>                qtt_CHECK(tens.sizes()[tens.dim() - 1] == tens.sizes()[tens.dim() - 2]);</div>
<div class="line"><a id="l00392" name="l00392"></a><span class="lineno">  392</span>                <span class="keyword">auto</span> <span class="keywordtype">id</span> = torch::eye(tens.sizes()[tens.dim() - 1]);</div>
<div class="line"><a id="l00393" name="l00393"></a><span class="lineno">  393</span>                qtt_CHECK(torch::allclose(<span class="keywordtype">id</span>, tens));</div>
<div class="line"><a id="l00394" name="l00394"></a><span class="lineno">  394</span>            }</div>
<div class="line"><a id="l00395" name="l00395"></a><span class="lineno">  395</span>            <span class="keywordflow">else</span></div>
<div class="line"><a id="l00396" name="l00396"></a><span class="lineno">  396</span>            {</div>
<div class="line"><a id="l00397" name="l00397"></a><span class="lineno">  397</span>                <span class="keyword">auto</span> zer = torch::zeros({tens.sizes()[tens.dim() - 2], tens.sizes()[tens.dim() - 1]});</div>
<div class="line"><a id="l00398" name="l00398"></a><span class="lineno">  398</span>                qtt_CHECK(torch::allclose(zer, tens));</div>
<div class="line"><a id="l00399" name="l00399"></a><span class="lineno">  399</span>            }</div>
<div class="line"><a id="l00400" name="l00400"></a><span class="lineno">  400</span>        }</div>
<div class="line"><a id="l00401" name="l00401"></a><span class="lineno">  401</span>    }</div>
<div class="line"><a id="l00402" name="l00402"></a><span class="lineno">  402</span>    qtt_SUBCASE(<span class="stringliteral">&quot;tensor decomposition&quot;</span>)</div>
<div class="line"><a id="l00403" name="l00403"></a><span class="lineno">  403</span>    {</div>
<div class="line"><a id="l00404" name="l00404"></a><span class="lineno">  404</span>        <span class="keyword">using</span> cqt = conserved::C&lt;5&gt;;</div>
<div class="line"><a id="l00405" name="l00405"></a><span class="lineno">  405</span>        <span class="keyword">using</span> index = btensor::index_list;</div>
<div class="line"><a id="l00406" name="l00406"></a><span class="lineno">  406</span>        <span class="keywordtype">double</span> tole = 1e-5;</div>
<div class="line"><a id="l00407" name="l00407"></a><span class="lineno">  407</span>        any_quantity selection_rule(cqt(0)); <span class="comment">// DMRJulia flux</span></div>
<div class="line"><a id="l00408" name="l00408"></a><span class="lineno">  408</span>        btensor A({{{2, cqt(0)}, {3, cqt(1)}},</div>
<div class="line"><a id="l00409" name="l00409"></a><span class="lineno">  409</span>                   {{1, cqt(1)}, {2, cqt(0)}, {3, cqt(-1)}, {1, cqt(1)}},</div>
<div class="line"><a id="l00410" name="l00410"></a><span class="lineno">  410</span>                   {{3, cqt(0)}, {2, cqt(-2)}, {2, cqt(-1)}}},</div>
<div class="line"><a id="l00411" name="l00411"></a><span class="lineno">  411</span>                  selection_rule);</div>
<div class="line"><a id="l00412" name="l00412"></a><span class="lineno">  412</span>        A.block({0, 0, 2}) = tole * torch::rand({2, 1, 2});</div>
<div class="line"><a id="l00413" name="l00413"></a><span class="lineno">  413</span>        A.block({0, 1, 0}) = tole * torch::rand({2, 2, 3});</div>
<div class="line"><a id="l00414" name="l00414"></a><span class="lineno">  414</span>        A.block({0, 3, 2}) = 0.1 * tole * torch::rand({2, 1, 2});</div>
<div class="line"><a id="l00415" name="l00415"></a><span class="lineno">  415</span>        A.block({1, 0, 1}) = tole * torch::rand({3, 1, 2});</div>
<div class="line"><a id="l00416" name="l00416"></a><span class="lineno">  416</span>        A.block({1, 1, 2}) = tole * torch::rand({3, 2, 2});</div>
<div class="line"><a id="l00417" name="l00417"></a><span class="lineno">  417</span>        A.block({1, 2, 0}) = 0.1 * tole * torch::rand({3, 3, 3});</div>
<div class="line"><a id="l00418" name="l00418"></a><span class="lineno">  418</span>        A.block({1, 3, 1}) = tole * torch::rand({3, 1, 2});</div>
<div class="line"><a id="l00419" name="l00419"></a><span class="lineno">  419</span>        <span class="comment">// fmt::print(&quot;A \n{}\n\n&quot;,A);</span></div>
<div class="line"><a id="l00420" name="l00420"></a><span class="lineno">  420</span>        qtt_REQUIRE_NOTHROW(<a class="code hl_function" href="classquantit_1_1btensor.html#a5d8897e8e51c880654c5d467b2b0a8bc">btensor::throw_bad_tensor</a>(A));</div>
<div class="line"><a id="l00421" name="l00421"></a><span class="lineno">  421</span>        qtt_SUBCASE(<span class="stringliteral">&quot;tensor singular decomposition&quot;</span>)</div>
<div class="line"><a id="l00422" name="l00422"></a><span class="lineno">  422</span>        {</div>
<div class="line"><a id="l00423" name="l00423"></a><span class="lineno">  423</span>            btensor U, d, V;</div>
<div class="line"><a id="l00424" name="l00424"></a><span class="lineno">  424</span>            qtt_REQUIRE_NOTHROW(std::tie(U, d, V) = svd(A, 1));</div>
<div class="line"><a id="l00425" name="l00425"></a><span class="lineno">  425</span>            <span class="comment">// fmt::print(&quot;U \n{}\n\n&quot;,U);</span></div>
<div class="line"><a id="l00426" name="l00426"></a><span class="lineno">  426</span>            <span class="comment">// fmt::print(&quot;d \n{}\n\n&quot;,d);</span></div>
<div class="line"><a id="l00427" name="l00427"></a><span class="lineno">  427</span>            <span class="comment">// fmt::print(&quot;V \n{}\n\n&quot;,V);</span></div>
<div class="line"><a id="l00428" name="l00428"></a><span class="lineno">  428</span>            <span class="keyword">auto</span> Ud = U.mul(d);</div>
<div class="line"><a id="l00429" name="l00429"></a><span class="lineno">  429</span>            <span class="comment">// fmt::print(&quot;Ud \n{}\n\n&quot;,Ud);</span></div>
<div class="line"><a id="l00430" name="l00430"></a><span class="lineno">  430</span>            <span class="keyword">auto</span> AA = tensordot(Ud, V.conj(), {U.dim() - 1}, {V.dim() - 1});</div>
<div class="line"><a id="l00431" name="l00431"></a><span class="lineno">  431</span>            <span class="comment">// fmt::print(&quot;AA \n{}\n\n&quot;,AA);</span></div>
<div class="line"><a id="l00432" name="l00432"></a><span class="lineno">  432</span>            <span class="keyword">auto</span> AA_it = AA.begin();</div>
<div class="line"><a id="l00433" name="l00433"></a><span class="lineno">  433</span>            <span class="keyword">auto</span> A_it = A.begin();</div>
<div class="line"><a id="l00434" name="l00434"></a><span class="lineno">  434</span>            qtt_REQUIRE(std::distance(AA_it, AA.end()) == std::distance(A_it, A.end()));</div>
<div class="line"><a id="l00435" name="l00435"></a><span class="lineno">  435</span>            <span class="keywordflow">while</span> (AA_it != AA.end())</div>
<div class="line"><a id="l00436" name="l00436"></a><span class="lineno">  436</span>            {</div>
<div class="line"><a id="l00437" name="l00437"></a><span class="lineno">  437</span>                <span class="keyword">auto</span> AA_ind = std::get&lt;0&gt;(*AA_it);</div>
<div class="line"><a id="l00438" name="l00438"></a><span class="lineno">  438</span>                <span class="keyword">auto</span> A_ind = std::get&lt;0&gt;(*A_it);</div>
<div class="line"><a id="l00439" name="l00439"></a><span class="lineno">  439</span>                <span class="keyword">auto</span> AA_tens = std::get&lt;1&gt;(*AA_it);</div>
<div class="line"><a id="l00440" name="l00440"></a><span class="lineno">  440</span>                <span class="keyword">auto</span> A_tens = std::get&lt;1&gt;(*A_it);</div>
<div class="line"><a id="l00441" name="l00441"></a><span class="lineno">  441</span>                qtt_CHECK(AA_ind == A_ind);</div>
<div class="line"><a id="l00442" name="l00442"></a><span class="lineno">  442</span>                qtt_CHECK(torch::allclose(AA_tens, A_tens));</div>
<div class="line"><a id="l00443" name="l00443"></a><span class="lineno">  443</span>                ++AA_it;</div>
<div class="line"><a id="l00444" name="l00444"></a><span class="lineno">  444</span>                ++A_it;</div>
<div class="line"><a id="l00445" name="l00445"></a><span class="lineno">  445</span>            }</div>
<div class="line"><a id="l00446" name="l00446"></a><span class="lineno">  446</span>        }</div>
<div class="line"><a id="l00447" name="l00447"></a><span class="lineno">  447</span>        qtt_SUBCASE(<span class="stringliteral">&quot;random tensor decomposition&quot;</span>)</div>
<div class="line"><a id="l00448" name="l00448"></a><span class="lineno">  448</span>        {</div>
<div class="line"><a id="l00449" name="l00449"></a><span class="lineno">  449</span>            <span class="keyword">using</span> cqt = conserved::C&lt;2&gt;;</div>
<div class="line"><a id="l00450" name="l00450"></a><span class="lineno">  450</span>            btensor dummy = rand({}, cqt(0));</div>
<div class="line"><a id="l00451" name="l00451"></a><span class="lineno">  451</span>            btensor X = quantit::rand({{{2, cqt(-2)}, {2, cqt(0)}, {2, cqt(2)}},</div>
<div class="line"><a id="l00452" name="l00452"></a><span class="lineno">  452</span>                                      {{1, cqt(1)}, {1, cqt(-1)}},</div>
<div class="line"><a id="l00453" name="l00453"></a><span class="lineno">  453</span>                                      {{1, cqt(1)}, {1, cqt(-1)}},</div>
<div class="line"><a id="l00454" name="l00454"></a><span class="lineno">  454</span>                                      {{2, cqt(2)}, {2, cqt(0)}, {2, cqt(-2)}}},</div>
<div class="line"><a id="l00455" name="l00455"></a><span class="lineno">  455</span>                                     cqt(0));</div>
<div class="line"><a id="l00456" name="l00456"></a><span class="lineno">  456</span>            <span class="keyword">auto</span> [U, d, V] = svd(X, 2);</div>
<div class="line"><a id="l00457" name="l00457"></a><span class="lineno">  457</span>            qtt_CHECK(tensordot(U, U.conj(), {0, 1, 2}, {0, 1, 2}).<a class="code hl_function" href="classquantit_1_1btensor.html#a01c490238e0022b585dc430b13ec7dd1">item</a>().toDouble() == doctest::Approx(d.sizes()[0]));</div>
<div class="line"><a id="l00458" name="l00458"></a><span class="lineno">  458</span>            qtt_CHECK(tensordot(V, V.conj(), {0, 1, 2}, {0, 1, 2}).<a class="code hl_function" href="classquantit_1_1btensor.html#a01c490238e0022b585dc430b13ec7dd1">item</a>().toDouble() == doctest::Approx(d.sizes()[0]));</div>
<div class="line"><a id="l00459" name="l00459"></a><span class="lineno">  459</span>            qtt_CHECK(tensordot(U, U.conj(), {2, 0, 1}, {2, 0, 1}).<a class="code hl_function" href="classquantit_1_1btensor.html#a01c490238e0022b585dc430b13ec7dd1">item</a>().toDouble() == doctest::Approx(d.sizes()[0]));</div>
<div class="line"><a id="l00460" name="l00460"></a><span class="lineno">  460</span>            qtt_CHECK(tensordot(V, V.conj(), {2, 0, 1}, {2, 0, 1}).<a class="code hl_function" href="classquantit_1_1btensor.html#a01c490238e0022b585dc430b13ec7dd1">item</a>().toDouble() == doctest::Approx(d.sizes()[0]));</div>
<div class="line"><a id="l00461" name="l00461"></a><span class="lineno">  461</span>            <span class="comment">// fmt::print(&quot;U shape {}\n\nV shape {}\n\n d {}\n\n&quot;,shape_from(U,dummy),shape_from(V,dummy),d);</span></div>
<div class="line"><a id="l00462" name="l00462"></a><span class="lineno">  462</span>            <span class="keyword">auto</span> U2 = U.reshape({2});</div>
<div class="line"><a id="l00463" name="l00463"></a><span class="lineno">  463</span>            <span class="keyword">auto</span> V2 = V.reshape({2});</div>
<div class="line"><a id="l00464" name="l00464"></a><span class="lineno">  464</span>            <span class="comment">// fmt::print(&quot;U {}\n\nV {}\n\n&quot;, tensordot(U2,U2.conj(), {1,0},{1,0}),tensordot(V2,V2.conj(),{1,0},{1,0}));</span></div>
<div class="line"><a id="l00465" name="l00465"></a><span class="lineno">  465</span>            qtt_CHECK(allclose(tensordot(U.mul(d), V.conj(), {2}, {2}), X));</div>
<div class="line"><a id="l00466" name="l00466"></a><span class="lineno">  466</span>            <span class="comment">// auto XX = tensordot(U.mul(d), V.conj(), {2}, {2});</span></div>
<div class="line"><a id="l00467" name="l00467"></a><span class="lineno">  467</span>            <span class="comment">// fmt::print(&quot;X\n{}\n\n&quot;, shape_from(X, dummy));</span></div>
<div class="line"><a id="l00468" name="l00468"></a><span class="lineno">  468</span>            <span class="comment">// fmt::print(&quot;reconstituded X\n{}\n\n&quot;, shape_from(XX, dummy));</span></div>
<div class="line"><a id="l00469" name="l00469"></a><span class="lineno">  469</span>            <span class="comment">// fmt::print(&quot;U\n{}\n\n&quot;, shape_from(U, dummy));</span></div>
<div class="line"><a id="l00470" name="l00470"></a><span class="lineno">  470</span>            <span class="comment">// fmt::print(&quot;d\n{}\n\n&quot;, shape_from(d, dummy));</span></div>
<div class="line"><a id="l00471" name="l00471"></a><span class="lineno">  471</span>            <span class="comment">// fmt::print(&quot;V\n{}\n\n&quot;, shape_from(V, dummy));</span></div>
<div class="line"><a id="l00472" name="l00472"></a><span class="lineno">  472</span>        }</div>
<div class="line"><a id="l00473" name="l00473"></a><span class="lineno">  473</span>        qtt_SUBCASE(<span class="stringliteral">&quot;truncating tensor singular decomposition&quot;</span>)</div>
<div class="line"><a id="l00474" name="l00474"></a><span class="lineno">  474</span>        {</div>
<div class="line"><a id="l00475" name="l00475"></a><span class="lineno">  475</span>            btensor U, d, V;</div>
<div class="line"><a id="l00476" name="l00476"></a><span class="lineno">  476</span>            qtt_REQUIRE_NOTHROW(std::tie(U, d, V) = svd(A, 1, tole));</div>
<div class="line"><a id="l00477" name="l00477"></a><span class="lineno">  477</span>            <span class="comment">// fmt::print(&quot;U \n{}\n\n&quot;,U);</span></div>
<div class="line"><a id="l00478" name="l00478"></a><span class="lineno">  478</span>            <span class="comment">// fmt::print(&quot;d \n{}\n\n&quot;,d);</span></div>
<div class="line"><a id="l00479" name="l00479"></a><span class="lineno">  479</span>            <span class="comment">// fmt::print(&quot;V \n{}\n\n&quot;,V);</span></div>
<div class="line"><a id="l00480" name="l00480"></a><span class="lineno">  480</span>            <span class="keyword">auto</span> AA = tensordot(U.mul(d), V.conj(), {U.dim() - 1}, {V.dim() - 1});</div>
<div class="line"><a id="l00481" name="l00481"></a><span class="lineno">  481</span>            <span class="comment">// fmt::print(&quot;AA \n{}\n\n&quot;,AA);</span></div>
<div class="line"><a id="l00482" name="l00482"></a><span class="lineno">  482</span>            <span class="keyword">auto</span> AA_it = AA.begin();</div>
<div class="line"><a id="l00483" name="l00483"></a><span class="lineno">  483</span>            <span class="keyword">auto</span> A_it = A.begin();</div>
<div class="line"><a id="l00484" name="l00484"></a><span class="lineno">  484</span>            qtt_REQUIRE(std::distance(AA_it, AA.end()) &lt;= std::distance(A_it, A.end()));</div>
<div class="line"><a id="l00485" name="l00485"></a><span class="lineno">  485</span>            <span class="keywordflow">while</span> (AA_it != AA.end())</div>
<div class="line"><a id="l00486" name="l00486"></a><span class="lineno">  486</span>            {</div>
<div class="line"><a id="l00487" name="l00487"></a><span class="lineno">  487</span>                <span class="keyword">auto</span> AA_ind = std::get&lt;0&gt;(*AA_it);</div>
<div class="line"><a id="l00488" name="l00488"></a><span class="lineno">  488</span>                <span class="keyword">auto</span> A_ind = std::get&lt;0&gt;(*A_it);</div>
<div class="line"><a id="l00489" name="l00489"></a><span class="lineno">  489</span>                <span class="keyword">auto</span> AA_tens = std::get&lt;1&gt;(*AA_it);</div>
<div class="line"><a id="l00490" name="l00490"></a><span class="lineno">  490</span>                <span class="keyword">auto</span> A_tens = std::get&lt;1&gt;(*A_it);</div>
<div class="line"><a id="l00491" name="l00491"></a><span class="lineno">  491</span>                <span class="keywordflow">if</span> (AA_ind == A_ind)</div>
<div class="line"><a id="l00492" name="l00492"></a><span class="lineno">  492</span>                {</div>
<div class="line"><a id="l00493" name="l00493"></a><span class="lineno">  493</span>                    qtt_CHECK(torch::all(torch::less(torch::abs(A_tens - AA_tens), tole)).item().to&lt;bool&gt;());</div>
<div class="line"><a id="l00494" name="l00494"></a><span class="lineno">  494</span>                    <span class="comment">// if (not torch::all(torch::less(torch::abs(A_tens-AA_tens),tol)).item().to&lt;bool&gt;())</span></div>
<div class="line"><a id="l00495" name="l00495"></a><span class="lineno">  495</span>                    <span class="comment">// {</span></div>
<div class="line"><a id="l00496" name="l00496"></a><span class="lineno">  496</span>                    <span class="comment">//  fmt::print(&quot;reduction check failed: ind {}\n&quot;,A_ind);</span></div>
<div class="line"><a id="l00497" name="l00497"></a><span class="lineno">  497</span>                    <span class="comment">//  fmt::print(&quot;absolute difference \n{}\n\n&quot;,torch::abs(A_tens-AA_tens));</span></div>
<div class="line"><a id="l00498" name="l00498"></a><span class="lineno">  498</span>                    <span class="comment">// }</span></div>
<div class="line"><a id="l00499" name="l00499"></a><span class="lineno">  499</span>                    <span class="comment">// qtt_CHECK(torch::allclose(AA_tens, A_tens, tol, tol));</span></div>
<div class="line"><a id="l00500" name="l00500"></a><span class="lineno">  500</span>                    ++AA_it;</div>
<div class="line"><a id="l00501" name="l00501"></a><span class="lineno">  501</span>                    ++A_it;</div>
<div class="line"><a id="l00502" name="l00502"></a><span class="lineno">  502</span>                }</div>
<div class="line"><a id="l00503" name="l00503"></a><span class="lineno">  503</span>                <span class="keywordflow">else</span></div>
<div class="line"><a id="l00504" name="l00504"></a><span class="lineno">  504</span>                {</div>
<div class="line"><a id="l00505" name="l00505"></a><span class="lineno">  505</span>                    <span class="comment">// if a block from A is literally not present in AA, then that block must be all zeros to the</span></div>
<div class="line"><a id="l00506" name="l00506"></a><span class="lineno">  506</span>                    <span class="comment">// tol.</span></div>
<div class="line"><a id="l00507" name="l00507"></a><span class="lineno">  507</span>                    qtt_CHECK(torch::all(torch::less(torch::abs(A_tens), tole)).item().to&lt;bool&gt;());</div>
<div class="line"><a id="l00508" name="l00508"></a><span class="lineno">  508</span>                    <span class="comment">// if (not torch::all(torch::less(torch::abs(A_tens),tol)).item().to&lt;bool&gt;())</span></div>
<div class="line"><a id="l00509" name="l00509"></a><span class="lineno">  509</span>                    <span class="comment">// {</span></div>
<div class="line"><a id="l00510" name="l00510"></a><span class="lineno">  510</span>                    <span class="comment">//  fmt::print(&quot;block removed check failed: ind {}\n&quot;,A_ind);</span></div>
<div class="line"><a id="l00511" name="l00511"></a><span class="lineno">  511</span>                    <span class="comment">//  fmt::print(&quot;a_tens \n{}\n\n&quot;,A_tens);</span></div>
<div class="line"><a id="l00512" name="l00512"></a><span class="lineno">  512</span>                    <span class="comment">// }</span></div>
<div class="line"><a id="l00513" name="l00513"></a><span class="lineno">  513</span>                    <span class="comment">// qtt_CHECK(torch::allclose(A_tens,torch::zeros_like(A_tens),tol,tol));</span></div>
<div class="line"><a id="l00514" name="l00514"></a><span class="lineno">  514</span>                    <span class="keywordtype">bool</span> AAlessA = AA_ind &lt; A_ind;</div>
<div class="line"><a id="l00515" name="l00515"></a><span class="lineno">  515</span>                    AA_it += AAlessA;</div>
<div class="line"><a id="l00516" name="l00516"></a><span class="lineno">  516</span>                    A_it += !AAlessA;</div>
<div class="line"><a id="l00517" name="l00517"></a><span class="lineno">  517</span>                }</div>
<div class="line"><a id="l00518" name="l00518"></a><span class="lineno">  518</span>            }</div>
<div class="line"><a id="l00519" name="l00519"></a><span class="lineno">  519</span>        }</div>
<div class="line"><a id="l00520" name="l00520"></a><span class="lineno">  520</span>        qtt_SUBCASE(<span class="stringliteral">&quot;truncating smaller tensor singular decomposition&quot;</span>)</div>
<div class="line"><a id="l00521" name="l00521"></a><span class="lineno">  521</span>        {</div>
<div class="line"><a id="l00522" name="l00522"></a><span class="lineno">  522</span>            btensor U, d, V;</div>
<div class="line"><a id="l00523" name="l00523"></a><span class="lineno">  523</span>            A.mul_(0.3);</div>
<div class="line"><a id="l00524" name="l00524"></a><span class="lineno">  524</span>            qtt_REQUIRE_NOTHROW(std::tie(U, d, V) = svd(A, 1, tole));</div>
<div class="line"><a id="l00525" name="l00525"></a><span class="lineno">  525</span>            <span class="comment">// fmt::print(&quot;U \n{}\n\n&quot;,U);</span></div>
<div class="line"><a id="l00526" name="l00526"></a><span class="lineno">  526</span>            <span class="comment">// fmt::print(&quot;d \n{}\n\n&quot;,d);</span></div>
<div class="line"><a id="l00527" name="l00527"></a><span class="lineno">  527</span>            <span class="comment">// fmt::print(&quot;V \n{}\n\n&quot;,V);</span></div>
<div class="line"><a id="l00528" name="l00528"></a><span class="lineno">  528</span>            <span class="keyword">auto</span> AA = tensordot(U.mul(d), V.conj(), {U.dim() - 1}, {V.dim() - 1});</div>
<div class="line"><a id="l00529" name="l00529"></a><span class="lineno">  529</span>            <span class="comment">// fmt::print(&quot;AA \n{}\n\n&quot;,AA);</span></div>
<div class="line"><a id="l00530" name="l00530"></a><span class="lineno">  530</span>            <span class="keyword">auto</span> AA_it = AA.begin();</div>
<div class="line"><a id="l00531" name="l00531"></a><span class="lineno">  531</span>            <span class="keyword">auto</span> A_it = A.begin();</div>
<div class="line"><a id="l00532" name="l00532"></a><span class="lineno">  532</span>            qtt_REQUIRE(std::distance(AA_it, AA.end()) &lt;= std::distance(A_it, A.end()));</div>
<div class="line"><a id="l00533" name="l00533"></a><span class="lineno">  533</span>            <span class="keywordflow">while</span> (AA_it != AA.end())</div>
<div class="line"><a id="l00534" name="l00534"></a><span class="lineno">  534</span>            {</div>
<div class="line"><a id="l00535" name="l00535"></a><span class="lineno">  535</span>                <span class="keyword">auto</span> AA_ind = std::get&lt;0&gt;(*AA_it);</div>
<div class="line"><a id="l00536" name="l00536"></a><span class="lineno">  536</span>                <span class="keyword">auto</span> A_ind = std::get&lt;0&gt;(*A_it);</div>
<div class="line"><a id="l00537" name="l00537"></a><span class="lineno">  537</span>                <span class="keyword">auto</span> AA_tens = std::get&lt;1&gt;(*AA_it);</div>
<div class="line"><a id="l00538" name="l00538"></a><span class="lineno">  538</span>                <span class="keyword">auto</span> A_tens = std::get&lt;1&gt;(*A_it);</div>
<div class="line"><a id="l00539" name="l00539"></a><span class="lineno">  539</span>                <span class="keywordflow">if</span> (AA_ind == A_ind)</div>
<div class="line"><a id="l00540" name="l00540"></a><span class="lineno">  540</span>                {</div>
<div class="line"><a id="l00541" name="l00541"></a><span class="lineno">  541</span>                    qtt_CHECK(torch::all(torch::less(torch::abs(A_tens - AA_tens), tole)).item().to&lt;bool&gt;());</div>
<div class="line"><a id="l00542" name="l00542"></a><span class="lineno">  542</span>                    <span class="comment">// if (not torch::all(torch::less(torch::abs(A_tens-AA_tens),tol)).item().to&lt;bool&gt;())</span></div>
<div class="line"><a id="l00543" name="l00543"></a><span class="lineno">  543</span>                    <span class="comment">// {</span></div>
<div class="line"><a id="l00544" name="l00544"></a><span class="lineno">  544</span>                    <span class="comment">//  fmt::print(&quot;reduction check failed: ind {}\n&quot;,A_ind);</span></div>
<div class="line"><a id="l00545" name="l00545"></a><span class="lineno">  545</span>                    <span class="comment">//  fmt::print(&quot;absolute difference \n{}\n\n&quot;,torch::abs(A_tens-AA_tens));</span></div>
<div class="line"><a id="l00546" name="l00546"></a><span class="lineno">  546</span>                    <span class="comment">// }</span></div>
<div class="line"><a id="l00547" name="l00547"></a><span class="lineno">  547</span>                    <span class="comment">// qtt_CHECK(torch::allclose(AA_tens, A_tens, tol, tol));</span></div>
<div class="line"><a id="l00548" name="l00548"></a><span class="lineno">  548</span>                    ++AA_it;</div>
<div class="line"><a id="l00549" name="l00549"></a><span class="lineno">  549</span>                    ++A_it;</div>
<div class="line"><a id="l00550" name="l00550"></a><span class="lineno">  550</span>                }</div>
<div class="line"><a id="l00551" name="l00551"></a><span class="lineno">  551</span>                <span class="keywordflow">else</span></div>
<div class="line"><a id="l00552" name="l00552"></a><span class="lineno">  552</span>                {</div>
<div class="line"><a id="l00553" name="l00553"></a><span class="lineno">  553</span>                    <span class="comment">// if a block from A is literally not present in AA, then that block must be all zeros to the</span></div>
<div class="line"><a id="l00554" name="l00554"></a><span class="lineno">  554</span>                    <span class="comment">// tol.</span></div>
<div class="line"><a id="l00555" name="l00555"></a><span class="lineno">  555</span>                    qtt_CHECK(torch::all(torch::less(torch::abs(A_tens), tole)).item().to&lt;bool&gt;());</div>
<div class="line"><a id="l00556" name="l00556"></a><span class="lineno">  556</span>                    <span class="comment">// if (not torch::all(torch::less(torch::abs(A_tens),tol)).item().to&lt;bool&gt;())</span></div>
<div class="line"><a id="l00557" name="l00557"></a><span class="lineno">  557</span>                    <span class="comment">// {</span></div>
<div class="line"><a id="l00558" name="l00558"></a><span class="lineno">  558</span>                    <span class="comment">//  fmt::print(&quot;block removed check failed: ind {}\n&quot;,A_ind);</span></div>
<div class="line"><a id="l00559" name="l00559"></a><span class="lineno">  559</span>                    <span class="comment">//  fmt::print(&quot;a_tens \n{}\n\n&quot;,A_tens);</span></div>
<div class="line"><a id="l00560" name="l00560"></a><span class="lineno">  560</span>                    <span class="comment">// }</span></div>
<div class="line"><a id="l00561" name="l00561"></a><span class="lineno">  561</span>                    <span class="comment">// qtt_CHECK(torch::allclose(A_tens,torch::zeros_like(A_tens),tol,tol));</span></div>
<div class="line"><a id="l00562" name="l00562"></a><span class="lineno">  562</span>                    <span class="keywordtype">bool</span> AAlessA = AA_ind &lt; A_ind;</div>
<div class="line"><a id="l00563" name="l00563"></a><span class="lineno">  563</span>                    AA_it += AAlessA;</div>
<div class="line"><a id="l00564" name="l00564"></a><span class="lineno">  564</span>                    A_it += !AAlessA;</div>
<div class="line"><a id="l00565" name="l00565"></a><span class="lineno">  565</span>                }</div>
<div class="line"><a id="l00566" name="l00566"></a><span class="lineno">  566</span>            }</div>
<div class="line"><a id="l00567" name="l00567"></a><span class="lineno">  567</span>        }</div>
<div class="line"><a id="l00568" name="l00568"></a><span class="lineno">  568</span>    }</div>
<div class="line"><a id="l00569" name="l00569"></a><span class="lineno">  569</span>}</div>
<div class="line"><a id="l00570" name="l00570"></a><span class="lineno">  570</span> </div>
<div class="line"><a id="l00571" name="l00571"></a><span class="lineno">  571</span>} <span class="comment">// namespace quantit</span></div>
<div class="line"><a id="l00572" name="l00572"></a><span class="lineno">  572</span> </div>
<div class="line"><a id="l00573" name="l00573"></a><span class="lineno">  573</span><span class="preprocessor">#endif </span><span class="comment">// BTENSORLINEARALGEBRA_H</span></div>
<div class="ttc" id="aclassquantit_1_1btensor_html"><div class="ttname"><a href="classquantit_1_1btensor.html">quantit::btensor</a></div><div class="ttdoc">btensor is a type meant to represent block sparse tensor with conservation laws. The conservation law...</div><div class="ttdef"><b>Definition:</b> btensor.h:106</div></div>
<div class="ttc" id="aclassquantit_1_1btensor_html_a01c490238e0022b585dc430b13ec7dd1"><div class="ttname"><a href="classquantit_1_1btensor.html#a01c490238e0022b585dc430b13ec7dd1">quantit::btensor::item</a></div><div class="ttdeci">btensor::Scalar item() const</div><div class="ttdoc">if the tensor contain a single element, return a scalar object.</div></div>
<div class="ttc" id="aclassquantit_1_1btensor_html_a5d8897e8e51c880654c5d467b2b0a8bc"><div class="ttname"><a href="classquantit_1_1btensor.html#a5d8897e8e51c880654c5d467b2b0a8bc">quantit::btensor::throw_bad_tensor</a></div><div class="ttdeci">static void throw_bad_tensor(const btensor &amp;)</div><div class="ttdoc">throw an error in any situation where check_tensor return a non-empty string</div></div>
<div class="ttc" id="astructquantit_1_1BOOL_html"><div class="ttname"><a href="structquantit_1_1BOOL.html">quantit::BOOL</a></div><div class="ttdoc">A bool type with no implicit conversion from arithmetic types.</div><div class="ttdef"><b>Definition:</b> LinearAlgebra.h:31</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.3
</small></address>
</body>
</html>
