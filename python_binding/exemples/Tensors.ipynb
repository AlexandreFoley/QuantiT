{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import quantit as qtt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Quantit offer several factory function to generate tensors,\n",
    "and several possible conservation laws.\n",
    "Currently The following consevations law can be used without writing any C++ extensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function quantit.quantit.conserved.PyCapsule.C2C6>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtt.conserved.Z\n",
    "qtt.conserved.ZC2\n",
    "qtt.conserved.ZC3\n",
    "qtt.conserved.ZC4\n",
    "qtt.conserved.ZC5\n",
    "qtt.conserved.ZC6\n",
    "qtt.conserved.ZZ\n",
    "qtt.conserved.ZZC2\n",
    "qtt.conserved.ZZC3\n",
    "qtt.conserved.ZZC4\n",
    "qtt.conserved.ZZC5\n",
    "qtt.conserved.ZZC6\n",
    "qtt.conserved.C2\n",
    "qtt.conserved.C3\n",
    "qtt.conserved.C4\n",
    "qtt.conserved.C5\n",
    "qtt.conserved.C6\n",
    "qtt.conserved.C2C2\n",
    "qtt.conserved.C2C3\n",
    "qtt.conserved.C2C4\n",
    "qtt.conserved.C2C5\n",
    "qtt.conserved.C2C6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The Z stand for the natural numbers, It is good for conserved values can be mapped onto positive or negative values, zero included, such as z-axis angular momentum and particle number.\n",
    "The C stands for cyclical, and the number following it is the length of the cycle.\n",
    "For exemple C6 can take values from 0 to 5, and could be used to quantify the momentum of a particle on a 6 sites periodic system, such as an hexagonal plaquette.\n",
    "qtt.conserved.ZZ means that our conservation law can be specified by 2 integers. For exemple, this particular one is pertinent when both particle and spin is conserved.\n",
    "\n",
    "Those are so-called Abelian conservation laws, because they relate to abelian symmetry groups.\n",
    "The key property of such conserved quantity is that the tensor product of two states with well defined conserved quantities also has a well defined conserved conserved quantities.\n",
    "Such is not the case for every conserved quantities. For exemple, the total angular momentum doesn't, and isn't described by an Abelian group.\n",
    "\n",
    "A btensor (block tensor) defined by QuantiT is built of blocks of the same rank has the overall tensor. In essence,\n",
    "the full tensor is subdivided into sections along each of its dimensions. Each of the section has an associated conserved quantity and size.\n",
    "The blocks are formed by the intersection of the section in each dimensions. Each block has a one conserved quantity on each of its dimensions.\n",
    "Only the blocks that respect a selection rule are allowed to have non-zero elements.\n",
    "A block respect the selection rule if the conserved quantities of each of its dimensions sums up to a predetermined value.\n",
    "Forbiden blocks are not explicitly stored and permitted blocks of zeros need not be explicitly stored.\n",
    "\n",
    " exemple with a rank 2 tensor (matrix) of the inner structure\n",
    " of this type:\n",
    "\n",
    "\n",
    "````\n",
    "              S0,0 │ S0,1 │ S0,2 │ S0,3\n",
    "             ╔═════╪══════╪══════╪═════╗\n",
    "             ║     │      │      │     ║\n",
    "         S1,0║(0,0)│ (0,1)│ (0,2)│(0,3)║\n",
    "             ║     │      │      │     ║\n",
    "            ─╫─────┼──────┼──────┼─────╢\n",
    "             ║     │      │      │     ║\n",
    "             ║     │      │      │     ║\n",
    "         S1,1║(1,0)│ (1,1)│ (1,2)│(1,3)║\n",
    "             ║     │      │      │     ║\n",
    "             ║     │      │      │     ║\n",
    "             ║     │      │      │     ║\n",
    "            ─╫─────┼──────┼──────┼─────╢\n",
    "             ║     │      │      │     ║\n",
    "             ║     │      │      │     ║\n",
    "         S1,2║(2,0)│ (2,1)│ (2,2)│(2,3)║\n",
    "             ║     │      │      │     ║\n",
    "             ║     │      │      │     ║\n",
    "             ║     │      │      │     ║\n",
    "             ╚═════╧══════╧══════╧═════╝\n",
    "````\n",
    "In the preceding exemple, the rows are separated in 4 sections, and the columns in 3 sections.\n",
    "This make up to 12 blocks, that we label by section.\n",
    "Let's consider that the conserved quantity is simply an integer under the addition,that the column sections [-2,-1,1], the row sections have the conserved quantity [1,2,3,-1] and the selection rule is 0. In that case, only\n",
    "the blocks [(1,0),(0,1),(2,3)] can be non-zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to build a block tensor we must specify its shape:\n",
    "Each dimension of the tensor is defined by a list of conserved quantites and sizes.\n",
    "Let's consider a vector as an exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = qtt.conserved.Z\n",
    "V = qtt.sparse_zeros([[(2, Z(0)), (3, Z(1)), (1, Z(-1))]], Z(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The tensor thus constructed is empty, it has 6 elements and the selection rules is Z(1).\n",
    " The first 2 element of the vector are associated with the conserved quantity Z(0), the next three Z(1) and the last one with Z(-1).\n",
    " Only the 3 middle elements can ever differ from zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FermionShape = qtt.btensor([[(1, Z(0)), (2, Z(1)), (1, Z(2))]], Z(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Fermions shape describe the shape a ket half-spin fermions on a single site could take.\n",
    " This second exemple call a constructor of btensor instead of a factory function,\n",
    " and it build a vector in the local hilbert space of electrons.\n",
    " This constructor is equivalent to sparse_zero.\n",
    " This vector has 4 elements, one with 0 particles, 2 with one particles, and one with two particles.\n",
    "\n",
    " Complex conjugation of btensor also inverse the conserved quantities. Conjugating ``FermionShape`` tensor lends us the shape a bra should have.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Z(0)], [Z(-1)], [Z(-2)]]\n"
     ]
    }
   ],
   "source": [
    "ConjFermionShape = FermionShape.conj()\n",
    "print([x for x in ConjFermionShape.sections_quantity(0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of tensor can be composed into tensors of higher rank.\n",
    "From the previous two vector shape, we can construct the shape of an operator in that Hilbert space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of electron's local hilber space, with particle number conservation:\n",
      " btensor rank 2\n",
      " selection rule [Z(0)]\n",
      " number of sections by dim [3, 3]\n",
      " sections sizes [1, 2, 1, 1, 2, 1]\n",
      " sections conserved quantity [[Z(0)], [Z(1)], [Z(2)], [Z(0)], [Z(-1)], [Z(-2)]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Hilb_operatorShape = qtt.shape_from([FermionShape, ConjFermionShape])\n",
    "print(\"Shape of electron's local hilber space, with particle number conservation:\\n\", Hilb_operatorShape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a few different way to construct a tensor,\n",
    "We will construct the fermion annihilation and creation operators to demonstrate 3. \n",
    "Block by block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_up btensor rank 2\n",
      " selection rule [Z(-1)]\n",
      " number of sections by dim [3, 3]\n",
      " sections sizes [1, 2, 1, 1, 2, 1]\n",
      " sections conserved quantity [[Z(0)], [Z(1)], [Z(2)], [Z(0)], [Z(-1)], [Z(-2)]]\n",
      "block at [0, 1]\n",
      "  1  0\n",
      "[ CPUFloatType(1,2) ]\n",
      "block at [1, 2]\n",
      "  0\n",
      " 1\n",
      "[ CPUFloatType(2,1) ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c_up = qtt.sparse_zeros_like(Hilb_operatorShape) #We create a new empty tensor with the same shape as Hilb_operatorShape\n",
    "c_up.set_selection_rule_(Z(-1)) #we set the selection rule to -1: \n",
    "# only the blocks that reduce the number of particle by one can be non-zero\n",
    "c_up.blocks[0, 1] = torch.Tensor([[1, 0]]) #we populate with the correct value the two relevent blocks\n",
    "c_up.blocks[1, 2] = torch.Tensor([[0], [1]])\n",
    "print(\"c_up\", c_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by converting a full tensor into a block tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_dn btensor rank 2\n",
      " selection rule [Z(-1)]\n",
      " number of sections by dim [3, 3]\n",
      " sections sizes [1, 2, 1, 1, 2, 1]\n",
      " sections conserved quantity [[Z(0)], [Z(1)], [Z(2)], [Z(0)], [Z(-1)], [Z(-2)]]\n",
      "block at [0, 1]\n",
      "  0  1\n",
      "[ CPUFloatType(1,2) ]\n",
      "block at [1, 2]\n",
      " -1\n",
      " 0\n",
      "[ CPUFloatType(2,1) ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c_dn = qtt.from_torch_tensor_like(\n",
    "    Hilb_operatorShape.set_selection_rule(Z(-1)),\n",
    "    torch.Tensor([[0, 0, 1, 0], [0, 0, 0, -1], [0, 0, 0, 0], [0, 0, 0, 0]]),\n",
    ")\n",
    "print(\"c_dn\", c_dn)\n",
    "# A downside of this second method is that null block that are allowed by the selection rule could be present.\n",
    "# it's not a concern in this particular case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by inserting lower rank tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "btensor rank 2\n",
      " selection rule [Z(0)]\n",
      " number of sections by dim [3, 3]\n",
      " sections sizes [1, 2, 1, 1, 2, 1]\n",
      " sections conserved quantity [[Z(0)], [Z(1)], [Z(2)], [Z(0)], [Z(-1)], [Z(-2)]]\n",
      "\n",
      "btensor rank 2\n",
      " selection rule [Z(0)]\n",
      " number of sections by dim [3, 3]\n",
      " sections sizes [1, 2, 1, 1, 2, 1]\n",
      " sections conserved quantity [[Z(0)], [Z(1)], [Z(2)], [Z(0)], [Z(-1)], [Z(-2)]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c_dagger_up = qtt.sparse_zeros_like(Hilb_operatorShape)\n",
    "c_dagger_dn = qtt.sparse_zeros_like(Hilb_operatorShape)\n",
    "\n",
    "c_dagger_up.basic_index_put_([-1,0],torch.Tensor([0,1,0,0]))\n",
    "c_dagger_up.basic_index_put_([-1,2],torch.Tensor([0,0,0,1]))\n",
    "\n",
    "c_dagger_dn.basic_index_put_([-1,0],torch.Tensor([0,0,1,0]))\n",
    "c_dagger_dn.basic_index_put_([-1,1],torch.Tensor([0,0,0,-1]))\n",
    "print(c_dagger_dn)\n",
    "print(c_dagger_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method *basic_index_put_* works by copying a lower rank tensor into a matching view into the target tensor. The view is specified using -1 for each dimension to be kept as is and an integer value other wise. The supplied values can be in the form of a torch tensor or a btensor of matching shape. When using a torch tensor, non-zero values that are disallowed in the target tensor are silently ignored. \n",
    "\n",
    "In the previous example, we insert values column by column into the creation operator. This method for filling in values in a tensor is used more extensively in the exemple MPO.py, to construct a rank 4 tensor from matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we construct the creation operators (again) and number operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "btensor rank 2\n",
      " selection rule [Z(1)]\n",
      " number of sections by dim [3, 3]\n",
      " sections sizes [1, 2, 1, 1, 2, 1]\n",
      " sections conserved quantity [[Z(0)], [Z(1)], [Z(2)], [Z(0)], [Z(-1)], [Z(-2)]]\n",
      "block at [1, 0]\n",
      "  1\n",
      " 0\n",
      "[ CPUFloatType(2,1) ]\n",
      "block at [2, 1]\n",
      "  0  1\n",
      "[ CPUFloatType(1,2) ]\n",
      "\n",
      "btensor rank 2\n",
      " selection rule [Z(1)]\n",
      " number of sections by dim [3, 3]\n",
      " sections sizes [1, 2, 1, 1, 2, 1]\n",
      " sections conserved quantity [[Z(0)], [Z(1)], [Z(2)], [Z(0)], [Z(-1)], [Z(-2)]]\n",
      "block at [1, 0]\n",
      "  0\n",
      " 1\n",
      "[ CPUFloatType(2,1) ]\n",
      "block at [2, 1]\n",
      " -1  0\n",
      "[ CPUFloatType(1,2) ]\n",
      "\n",
      "n_up  btensor rank 2\n",
      " selection rule [Z(0)]\n",
      " number of sections by dim [3, 3]\n",
      " sections sizes [1, 2, 1, 1, 2, 1]\n",
      " sections conserved quantity [[Z(0)], [Z(1)], [Z(2)], [Z(0)], [Z(-1)], [Z(-2)]]\n",
      "block at [1, 1]\n",
      "  1  0\n",
      " 0  0\n",
      "[ CPUFloatType(2,2) ]\n",
      "block at [2, 2]\n",
      "  1\n",
      "[ CPUFloatType(1,1) ]\n",
      "\n",
      "n_dn  btensor rank 2\n",
      " selection rule [Z(0)]\n",
      " number of sections by dim [3, 3]\n",
      " sections sizes [1, 2, 1, 1, 2, 1]\n",
      " sections conserved quantity [[Z(0)], [Z(1)], [Z(2)], [Z(0)], [Z(-1)], [Z(-2)]]\n",
      "block at [1, 1]\n",
      "  0  0\n",
      " 0  1\n",
      "[ CPUFloatType(2,2) ]\n",
      "block at [2, 2]\n",
      "  1\n",
      "[ CPUFloatType(1,1) ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c_up_dag = c_up.conj().t_()# t_ permute that last two dimensions of a tensor, it transpose matrices\n",
    "c_dn_dag = c_dn.conj().t_()# the underscore signifies that the operation is done \"in-place\" no new tensors created by the operation (conj already created a new one that t_ acts on )\n",
    "\n",
    "\n",
    "print(c_up_dag)\n",
    "print(c_dn_dag)\n",
    "\n",
    "n_up = qtt.tensordot(c_up_dag,c_up,dims=([1],[0]))\n",
    "n_dn = c_dn_dag.bmm(c_dn)\n",
    "\n",
    "print(\"n_up \", n_up)\n",
    "print(\"n_dn \",n_dn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created $n_\\uparrow$ using the tensordot method, and $n_\\downarrow$ using bmm. In this particular case, both operation are equivalent: they perform a matrix-matrix multiplication.\n",
    "In general, tensordot is for performing an arbitrary contraction of two tensors while bmm perform a batched matrix multiplication.\n",
    "\n",
    "Tensordot function by specifying 2 tensors and the dimension to contract with each other in a 2-tuple of lists named dims. \n",
    "\n",
    "bmm broadcast together the first N-2 dimension of two tensors, and performs a matrix multiplication on the last two.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factory functions\n",
    "\n",
    "Quantity implment a set of factory function to automatically generate tensors with a simple values. All of those function come in two flavors, one taking a shape description and selection rule, and one taking a btensor to encode the shape. the factory function that fill the btensors with values will only fill the block that are allowed by the specified selection rule\n",
    "\n",
    "Those factory function are the same set that are available for *torch.tensor*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function quantit.quantit.PyCapsule.randn_like>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtt.sparse_zeros\n",
    "qtt.sparse_zeros_like\n",
    "qtt.zeros\n",
    "qtt.zeros_like\n",
    "qtt.ones\n",
    "qtt.ones_like\n",
    "qtt.empty\n",
    "qtt.empty_like\n",
    "qtt.rand\n",
    "qtt.rand_like\n",
    "qtt.full\n",
    "qtt.full_like\n",
    "qtt.randint\n",
    "qtt.randint_like\n",
    "qtt.randn\n",
    "qtt.randn_like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting and element by element operations\n",
    "\n",
    "btensors support several broadcasting and element by element operations.\n",
    "\n",
    "basic arithmetic (+ - * /) and comparison operator (> >= < <= == !=) can be done between two tensors, with broacasting for size 1 or absent dimensions.\n",
    "\n",
    "The following function can be applied element by element to a tensor: \n",
    "- *sqrt* for the square root\n",
    "- *abs* for the absolute value\n",
    "- *sqrt_* for performing the square root computation in place\n",
    "- *abs_* for performing the absolute value in place\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear algebra and Reshaping\n",
    "\n",
    "Singular value decomposition and Eigenvalue decomposition are available in the *linalg* submodule of QuantiT.\n",
    "They are present in two flavor: batched and Tensor networks.\n",
    "\n",
    "The batched version are the equivalent of the methods implemented by torch, but take avantage of the block structure to reduce the numerical cost of the computation.\n",
    "\n",
    "The tensor network version of the functions implicitly reshape the supplied tensor into a matrix before performing the routine and undoes it before returning the result.\n",
    "\n",
    "Additionnaly the tensor network method can perform automatic truncation based on the values in the diagonal matrix produced by the decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U =  btensor rank 3\n",
      " selection rule [Z(-2)]\n",
      " number of sections by dim [3, 3, 3]\n",
      " sections sizes [1, 2, 1, 1, 2, 1, 1, 4, 1]\n",
      " sections conserved quantity [[Z(0)], [Z(1)], [Z(2)], [Z(0)], [Z(-1)], [Z(-2)], [Z(0)], [Z(-1)], [Z(-2)]]\n",
      "block at [0, 0, 2]\n",
      " (1,.,.) = \n",
      "  0.4680\n",
      "[ CPUFloatType(1,1,1) ]\n",
      "block at [0, 1, 1]\n",
      " (1,.,.) = \n",
      " -0.5225  0.6061  0.1906 -0.5687\n",
      " -0.4693 -0.7852  0.2391 -0.3256\n",
      "[ CPUFloatType(1,2,4) ]\n",
      "block at [0, 2, 0]\n",
      " (1,.,.) = \n",
      " -1\n",
      "[ CPUFloatType(1,1,1) ]\n",
      "block at [1, 1, 2]\n",
      " (1,.,.) = \n",
      "  0.4932\n",
      "  0.4615\n",
      "\n",
      "(2,.,.) = \n",
      "  0.3621\n",
      "  0.1759\n",
      "[ CPUFloatType(2,2,1) ]\n",
      "block at [1, 2, 1]\n",
      " (1,.,.) = \n",
      " -0.4266 -0.0395 -0.9024  0.0473\n",
      "\n",
      "(2,.,.) = \n",
      " -0.5700  0.1205  0.3037  0.7539\n",
      "[ CPUFloatType(2,1,4) ]\n",
      "block at [2, 2, 2]\n",
      " (1,.,.) = \n",
      "  0.4034\n",
      "[ CPUFloatType(1,1,1) ]\n",
      " \n",
      " d= btensor rank 1\n",
      " selection rule [Z(0)]\n",
      " number of sections by dim [3]\n",
      " sections sizes [1, 4, 1]\n",
      " sections conserved quantity [[Z(0)], [Z(0)], [Z(0)]]\n",
      "block at [0]\n",
      "  1.7459\n",
      "[ CPUFloatType(1) ]\n",
      "block at [1]\n",
      "  2.1753\n",
      " 0.7809\n",
      " 0.4695\n",
      " 0.0928\n",
      "[ CPUFloatType(4) ]\n",
      "block at [2]\n",
      "  1.7859\n",
      "[ CPUFloatType(1) ]\n",
      " \n",
      " V=  btensor rank 3\n",
      " selection rule [Z(0)]\n",
      " number of sections by dim [3, 3, 3]\n",
      " sections sizes [1, 2, 1, 1, 2, 1, 1, 4, 1]\n",
      " sections conserved quantity [[Z(0)], [Z(-1)], [Z(-2)], [Z(0)], [Z(1)], [Z(2)], [Z(0)], [Z(-1)], [Z(-2)]]\n",
      "block at [0, 0, 0]\n",
      " (1,.,.) = \n",
      " -0.5428\n",
      "[ CPUFloatType(1,1,1) ]\n",
      "block at [0, 1, 1]\n",
      " (1,.,.) = \n",
      " -0.7295 -0.2108 -0.5743 -0.3060\n",
      " -0.2213  0.1155 -0.2585  0.9332\n",
      "[ CPUFloatType(1,2,4) ]\n",
      "block at [0, 2, 2]\n",
      " (1,.,.) = \n",
      "  1\n",
      "[ CPUFloatType(1,1,1) ]\n",
      "block at [1, 1, 0]\n",
      " (1,.,.) = \n",
      " -0.4330\n",
      " -0.5383\n",
      "\n",
      "(2,.,.) = \n",
      " -0.1804\n",
      " -0.4256\n",
      "[ CPUFloatType(2,2,1) ]\n",
      "block at [1, 2, 1]\n",
      " (1,.,.) = \n",
      " -0.4859  0.7764  0.3877 -0.1039\n",
      "\n",
      "(2,.,.) = \n",
      " -0.4275 -0.5826  0.6731  0.1572\n",
      "[ CPUFloatType(2,1,4) ]\n",
      "block at [2, 2, 0]\n",
      " (1,.,.) = \n",
      " -0.1200\n",
      "[ CPUFloatType(1,1,1) ]\n",
      "\n",
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "X = qtt.rand_like(qtt.shape_from([c_dn,c_dn]))\n",
    "# A rank 4 matrix.\n",
    "\n",
    "U,d,V = qtt.linalg.svd(X,2,tol = 1e-3,min_size = 2 ,max_size = 100)\n",
    "\n",
    "#d is the diagonnal of the matrix of singular values D.\n",
    "print(\"U = \", U,'\\n d=',d,'\\n V= ',V)\n",
    "\n",
    "X_reconstructed = qtt.tensordot((U*d),V.conj(),dims = ([U.dim()-1],[V.dim()-1]))\n",
    "#We use broadcasting to do the U.D without building D explicitly.\n",
    "\n",
    "T = (X_reconstructed-X) > 1e-5 #we're currently working in single precision, so we can't be too stringent.\n",
    "\n",
    "print(qtt.any(T)) # we expect false.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last 3 argument are optionnal and serve to specify the parameters of the truncation: tol is the permitted reconstruction error using (by default) the Frobenius norm. min_size and max_size control the size new index without regards to the truncation error.\n",
    "\n",
    "The second argument specify the implicit matrix shape used: in this case the first 2 dimensions of the tensor are treated as the row of a matrix and rest are the columns.\n",
    "\n",
    "The eigenvalue decomposition can also be done if the split result in a hermitian matrix with *eigh* and the same interface.\n",
    "\n",
    "The reshaping that has taken place implicitly so far can be done explicitly using the function *qtt.reshape* and *qtt.reshape_as*. Lets do the tensor SVD using the batched SVD by explicitly reshaping the **X** tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mat = qtt.reshape(X,[2])\n",
    "\n",
    "Utmp,d,Vtmp = qtt.linalg.svd(X_mat)\n",
    "\n",
    "U_shape = qtt.shape_from([X.shape_from([-1,-1,0,0]),Utmp.shape_from([0,-1])])\n",
    "V_shape = qtt.shape_from([X.shape_from([0,0,-1,-1]).conj(),Vtmp.shape_from([0,-1])])\n",
    "\n",
    "U = qtt.reshape_as(Utmp,U_shape)\n",
    "V = qtt.reshape_as(Vtmp,V_shape)\n",
    "\n",
    "qtt.linalg.truncate(U,d,V,tol=1e-3,min=1,max=100,pow=2)#truncate function for SVD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the *qtt.reshape* function takes a list of integers to specify a new shape of a lower rank than the input tensor. It simply join together all the dimension in the intervals of dimension between the value in the list.\n",
    "\n",
    "In the previous exemple, the single *2* present means that dimensions [0,2[ are joined in a single dimension in the output, and [2,3] are joined in a single dimensions.\n",
    "\n",
    "A rank three tensor could be specified by writing\n",
    "\n",
    "*qtt.reshape(X,[1,2])* would join together the last 2 dimension of the tensor and leave the first 2 as they were. This method of reshaping can only reduce the rank of the tensor.\n",
    "\n",
    "To do an arbitrary reshape (including ones that increase the rank), one must specify completly the desired shape in the form a another btensor with said shape."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ca837fb18a45579a0202e4984e1cb487fce692c0fd801a466e53d66267a23a7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('3.9-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
